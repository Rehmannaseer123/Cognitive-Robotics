{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model, save_model\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Conv2D, GlobalMaxPooling2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR-10 dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (50000, 32, 32, 3)\n",
      "Size of training data:  50000\n",
      "Size of testing data:  10000\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape:', X_train.shape)\n",
    "\n",
    "print('Size of training data: ', X_train.shape[0])\n",
    "print('Size of testing data: ', X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test = to_categorical(y_test, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Perform Normalization\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the training data into training and validation sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_set, X_val, Y_train_set, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, zoom_range=0.2)\n",
    "train_generator = data_generator.flow(X_train_set, Y_train_set, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Model1(k, dr, lr):\n",
    "    \n",
    "    i = Input(shape = (32, 32, 3))\n",
    "\n",
    "    x = Conv2D(32, (k,k), activation= 'relu', padding='same')(i)\n",
    "    x = Conv2D(32, (k,k), activation= 'relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Dropout(dr)(x)\n",
    "\n",
    "    x = Conv2D(64, (k,k), activation= 'relu', padding='same')(x)\n",
    "    x = Conv2D(64, (k,k), activation= 'relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Dropout(dr)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(dr)(x)\n",
    "\n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(i,x)\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate = lr)\n",
    "    \n",
    "    model.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model summary with filter size as 3x3, dropout rate as 0.20 and learning rate as 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              4195328   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4271146 (16.29 MB)\n",
      "Trainable params: 4271146 (16.29 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create_Model1(3, 0.20, 0.01).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_sizes = [3, 5]\n",
    "dropout_rates = [0.2, 0.35, 0.5]\n",
    "learning_rates = [0.01, 0.001, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for filter_size in filter_sizes:\n",
    "    \n",
    "    for dropout_rate in dropout_rates:\n",
    "        \n",
    "        for learning_rate in learning_rates:\n",
    "            \n",
    "            results[filter_size, dropout_rate, learning_rate] = {'accuracy': None,  'loss': None, 'history': None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_combination = [ [0, 0, 0], [0, 0, None] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COMBINATION: filter_size=3, dropout_rate=0.2, learning_rate=0.01\n",
      "Epoch 1/40\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.5431 - accuracy: 0.0984\n",
      "Epoch 1: val_accuracy improved from -inf to 0.09330, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 139ms/step - loss: 2.5431 - accuracy: 0.0984 - val_loss: 2.3036 - val_accuracy: 0.0933\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - ETA: 0s - loss: 2.3034 - accuracy: 0.0987\n",
      "Epoch 2: val_accuracy improved from 0.09330 to 0.10300, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 42s 134ms/step - loss: 2.3034 - accuracy: 0.0987 - val_loss: 2.3027 - val_accuracy: 0.1030\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3031 - accuracy: 0.1015\n",
      "Epoch 3: val_accuracy did not improve from 0.10300\n",
      "312/312 [==============================] - 42s 135ms/step - loss: 2.3031 - accuracy: 0.1015 - val_loss: 2.3038 - val_accuracy: 0.0933\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3032 - accuracy: 0.0985\n",
      "Epoch 4: val_accuracy improved from 0.10300 to 0.10400, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 54s 173ms/step - loss: 2.3032 - accuracy: 0.0985 - val_loss: 2.3034 - val_accuracy: 0.1040\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3032 - accuracy: 0.1007\n",
      "Epoch 5: val_accuracy did not improve from 0.10400\n",
      "312/312 [==============================] - 46s 147ms/step - loss: 2.3032 - accuracy: 0.1007 - val_loss: 2.3031 - val_accuracy: 0.1017\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3034 - accuracy: 0.1000\n",
      "Epoch 6: val_accuracy did not improve from 0.10400\n",
      "312/312 [==============================] - 43s 137ms/step - loss: 2.3034 - accuracy: 0.1000 - val_loss: 2.3029 - val_accuracy: 0.1015\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3032 - accuracy: 0.1005\n",
      "Epoch 7: val_accuracy did not improve from 0.10400\n",
      "312/312 [==============================] - 43s 138ms/step - loss: 2.3032 - accuracy: 0.1005 - val_loss: 2.3032 - val_accuracy: 0.0979\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.0996\n",
      "Epoch 8: val_accuracy did not improve from 0.10400\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 2.3033 - accuracy: 0.0996 - val_loss: 2.3033 - val_accuracy: 0.0933\n",
      "Epoch 9/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.0982\n",
      "Epoch 9: val_accuracy did not improve from 0.10400\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 2.3033 - accuracy: 0.0982 - val_loss: 2.3039 - val_accuracy: 0.0979\n",
      "Epoch 9: early stopping\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 2.3034 - accuracy: 0.1040\n",
      "COMBINATION BEST ACCURACY:  0.10400000214576721\n",
      "\n",
      "COMBINATION: filter_size=3, dropout_rate=0.2, learning_rate=0.001\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.7710 - accuracy: 0.3460\n",
      "Epoch 1: val_accuracy improved from -inf to 0.45310, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.7710 - accuracy: 0.3460 - val_loss: 1.5117 - val_accuracy: 0.4531\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4470 - accuracy: 0.4777\n",
      "Epoch 2: val_accuracy improved from 0.45310 to 0.55360, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.4470 - accuracy: 0.4777 - val_loss: 1.2655 - val_accuracy: 0.5536\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2928 - accuracy: 0.5349\n",
      "Epoch 3: val_accuracy improved from 0.55360 to 0.60920, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.2928 - accuracy: 0.5349 - val_loss: 1.0910 - val_accuracy: 0.6092\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1992 - accuracy: 0.5700\n",
      "Epoch 4: val_accuracy improved from 0.60920 to 0.63000, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 1.1992 - accuracy: 0.5700 - val_loss: 1.0599 - val_accuracy: 0.6300\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1233 - accuracy: 0.5986\n",
      "Epoch 5: val_accuracy improved from 0.63000 to 0.67080, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.1233 - accuracy: 0.5986 - val_loss: 0.9348 - val_accuracy: 0.6708\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0642 - accuracy: 0.6222\n",
      "Epoch 6: val_accuracy improved from 0.67080 to 0.67710, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 46s 149ms/step - loss: 1.0642 - accuracy: 0.6222 - val_loss: 0.9250 - val_accuracy: 0.6771\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0182 - accuracy: 0.6396\n",
      "Epoch 7: val_accuracy did not improve from 0.67710\n",
      "312/312 [==============================] - 49s 156ms/step - loss: 1.0182 - accuracy: 0.6396 - val_loss: 0.9922 - val_accuracy: 0.6528\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9823 - accuracy: 0.6539\n",
      "Epoch 8: val_accuracy improved from 0.67710 to 0.71420, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 47s 149ms/step - loss: 0.9823 - accuracy: 0.6539 - val_loss: 0.8280 - val_accuracy: 0.7142\n",
      "Epoch 9/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9291 - accuracy: 0.6726\n",
      "Epoch 9: val_accuracy did not improve from 0.71420\n",
      "312/312 [==============================] - 46s 148ms/step - loss: 0.9291 - accuracy: 0.6726 - val_loss: 0.8239 - val_accuracy: 0.7096\n",
      "Epoch 10/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9059 - accuracy: 0.6795\n",
      "Epoch 10: val_accuracy improved from 0.71420 to 0.71750, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 46s 147ms/step - loss: 0.9059 - accuracy: 0.6795 - val_loss: 0.8047 - val_accuracy: 0.7175\n",
      "Epoch 11/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8726 - accuracy: 0.6933\n",
      "Epoch 11: val_accuracy improved from 0.71750 to 0.73120, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 46s 148ms/step - loss: 0.8726 - accuracy: 0.6933 - val_loss: 0.7722 - val_accuracy: 0.7312\n",
      "Epoch 12/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8525 - accuracy: 0.6994\n",
      "Epoch 12: val_accuracy did not improve from 0.73120\n",
      "312/312 [==============================] - 47s 150ms/step - loss: 0.8525 - accuracy: 0.6994 - val_loss: 0.7658 - val_accuracy: 0.7303\n",
      "Epoch 13/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8310 - accuracy: 0.7088\n",
      "Epoch 13: val_accuracy improved from 0.73120 to 0.75100, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 46s 147ms/step - loss: 0.8310 - accuracy: 0.7088 - val_loss: 0.7177 - val_accuracy: 0.7510\n",
      "Epoch 14/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8134 - accuracy: 0.7141\n",
      "Epoch 14: val_accuracy improved from 0.75100 to 0.75460, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 46s 148ms/step - loss: 0.8134 - accuracy: 0.7141 - val_loss: 0.7091 - val_accuracy: 0.7546\n",
      "Epoch 15/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7964 - accuracy: 0.7196\n",
      "Epoch 15: val_accuracy did not improve from 0.75460\n",
      "312/312 [==============================] - 46s 146ms/step - loss: 0.7964 - accuracy: 0.7196 - val_loss: 0.8039 - val_accuracy: 0.7316\n",
      "Epoch 16/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7801 - accuracy: 0.7282\n",
      "Epoch 16: val_accuracy improved from 0.75460 to 0.76490, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 46s 148ms/step - loss: 0.7801 - accuracy: 0.7282 - val_loss: 0.6681 - val_accuracy: 0.7649\n",
      "Epoch 17/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7680 - accuracy: 0.7291\n",
      "Epoch 17: val_accuracy did not improve from 0.76490\n",
      "312/312 [==============================] - 45s 144ms/step - loss: 0.7680 - accuracy: 0.7291 - val_loss: 0.7249 - val_accuracy: 0.7503\n",
      "Epoch 18/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7522 - accuracy: 0.7349\n",
      "Epoch 18: val_accuracy did not improve from 0.76490\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 0.7522 - accuracy: 0.7349 - val_loss: 0.7802 - val_accuracy: 0.7365\n",
      "Epoch 19/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7462 - accuracy: 0.7374\n",
      "Epoch 19: val_accuracy improved from 0.76490 to 0.77000, saving model to cnn_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 44s 142ms/step - loss: 0.7462 - accuracy: 0.7374 - val_loss: 0.6825 - val_accuracy: 0.7700\n",
      "Epoch 20/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7349 - accuracy: 0.7414\n",
      "Epoch 20: val_accuracy improved from 0.77000 to 0.77520, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 0.7349 - accuracy: 0.7414 - val_loss: 0.6618 - val_accuracy: 0.7752\n",
      "Epoch 21/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7195 - accuracy: 0.7474\n",
      "Epoch 21: val_accuracy did not improve from 0.77520\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 0.7195 - accuracy: 0.7474 - val_loss: 0.7610 - val_accuracy: 0.7489\n",
      "Epoch 22/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7204 - accuracy: 0.7485\n",
      "Epoch 22: val_accuracy did not improve from 0.77520\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 0.7204 - accuracy: 0.7485 - val_loss: 0.6857 - val_accuracy: 0.7672\n",
      "Epoch 23/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7091 - accuracy: 0.7506\n",
      "Epoch 23: val_accuracy improved from 0.77520 to 0.78450, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 0.7091 - accuracy: 0.7506 - val_loss: 0.6194 - val_accuracy: 0.7845\n",
      "Epoch 24/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.7574\n",
      "Epoch 24: val_accuracy did not improve from 0.78450\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 0.6934 - accuracy: 0.7574 - val_loss: 0.6688 - val_accuracy: 0.7709\n",
      "Epoch 25/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6902 - accuracy: 0.7601\n",
      "Epoch 25: val_accuracy did not improve from 0.78450\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 0.6902 - accuracy: 0.7601 - val_loss: 0.6807 - val_accuracy: 0.7748\n",
      "Epoch 26/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6800 - accuracy: 0.7631\n",
      "Epoch 26: val_accuracy did not improve from 0.78450\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 0.6800 - accuracy: 0.7631 - val_loss: 0.6438 - val_accuracy: 0.7803\n",
      "Epoch 27/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6757 - accuracy: 0.7630\n",
      "Epoch 27: val_accuracy did not improve from 0.78450\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 0.6757 - accuracy: 0.7630 - val_loss: 0.6654 - val_accuracy: 0.7698\n",
      "Epoch 28/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6658 - accuracy: 0.7657\n",
      "Epoch 28: val_accuracy did not improve from 0.78450\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 0.6658 - accuracy: 0.7657 - val_loss: 0.6390 - val_accuracy: 0.7829\n",
      "Epoch 28: early stopping\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6194 - accuracy: 0.7845\n",
      "COMBINATION BEST ACCURACY:  0.784500002861023\n",
      "\n",
      "COMBINATION: filter_size=3, dropout_rate=0.2, learning_rate=0.0001\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.9697 - accuracy: 0.2784\n",
      "Epoch 1: val_accuracy improved from -inf to 0.39760, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 142ms/step - loss: 1.9697 - accuracy: 0.2784 - val_loss: 1.6890 - val_accuracy: 0.3976\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.7216 - accuracy: 0.3730\n",
      "Epoch 2: val_accuracy improved from 0.39760 to 0.44180, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.7216 - accuracy: 0.3730 - val_loss: 1.5426 - val_accuracy: 0.4418\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.6288 - accuracy: 0.4041\n",
      "Epoch 3: val_accuracy improved from 0.44180 to 0.46790, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.6288 - accuracy: 0.4041 - val_loss: 1.4840 - val_accuracy: 0.4679\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5713 - accuracy: 0.4285\n",
      "Epoch 4: val_accuracy improved from 0.46790 to 0.49590, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 1.5713 - accuracy: 0.4285 - val_loss: 1.4014 - val_accuracy: 0.4959\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5242 - accuracy: 0.4475\n",
      "Epoch 5: val_accuracy improved from 0.49590 to 0.52850, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 144ms/step - loss: 1.5242 - accuracy: 0.4475 - val_loss: 1.3288 - val_accuracy: 0.5285\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4767 - accuracy: 0.4671\n",
      "Epoch 6: val_accuracy did not improve from 0.52850\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.4767 - accuracy: 0.4671 - val_loss: 1.4018 - val_accuracy: 0.5038\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4518 - accuracy: 0.4800\n",
      "Epoch 7: val_accuracy improved from 0.52850 to 0.54210, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.4518 - accuracy: 0.4800 - val_loss: 1.2922 - val_accuracy: 0.5421\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4110 - accuracy: 0.4928\n",
      "Epoch 8: val_accuracy did not improve from 0.54210\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 1.4110 - accuracy: 0.4928 - val_loss: 1.2840 - val_accuracy: 0.5407\n",
      "Epoch 9/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3824 - accuracy: 0.5021\n",
      "Epoch 9: val_accuracy improved from 0.54210 to 0.54490, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 1.3824 - accuracy: 0.5021 - val_loss: 1.2679 - val_accuracy: 0.5449\n",
      "Epoch 10/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3512 - accuracy: 0.5146\n",
      "Epoch 10: val_accuracy improved from 0.54490 to 0.56680, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 144ms/step - loss: 1.3512 - accuracy: 0.5146 - val_loss: 1.2176 - val_accuracy: 0.5668\n",
      "Epoch 11/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3219 - accuracy: 0.5249\n",
      "Epoch 11: val_accuracy improved from 0.56680 to 0.56880, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 46s 147ms/step - loss: 1.3219 - accuracy: 0.5249 - val_loss: 1.2298 - val_accuracy: 0.5688\n",
      "Epoch 12/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3026 - accuracy: 0.5350\n",
      "Epoch 12: val_accuracy improved from 0.56880 to 0.58650, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 46s 148ms/step - loss: 1.3026 - accuracy: 0.5350 - val_loss: 1.1926 - val_accuracy: 0.5865\n",
      "Epoch 13/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2728 - accuracy: 0.5469\n",
      "Epoch 13: val_accuracy improved from 0.58650 to 0.58930, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 1.2728 - accuracy: 0.5469 - val_loss: 1.1655 - val_accuracy: 0.5893\n",
      "Epoch 14/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2542 - accuracy: 0.5526\n",
      "Epoch 14: val_accuracy did not improve from 0.58930\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 1.2542 - accuracy: 0.5526 - val_loss: 1.1644 - val_accuracy: 0.5830\n",
      "Epoch 15/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2333 - accuracy: 0.5576\n",
      "Epoch 15: val_accuracy improved from 0.58930 to 0.59880, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 1.2333 - accuracy: 0.5576 - val_loss: 1.1208 - val_accuracy: 0.5988\n",
      "Epoch 16/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2127 - accuracy: 0.5670\n",
      "Epoch 16: val_accuracy improved from 0.59880 to 0.61490, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 1.2127 - accuracy: 0.5670 - val_loss: 1.0957 - val_accuracy: 0.6149\n",
      "Epoch 17/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1951 - accuracy: 0.5750\n",
      "Epoch 17: val_accuracy did not improve from 0.61490\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 1.1951 - accuracy: 0.5750 - val_loss: 1.1431 - val_accuracy: 0.5976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1754 - accuracy: 0.5809\n",
      "Epoch 18: val_accuracy did not improve from 0.61490\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 1.1754 - accuracy: 0.5809 - val_loss: 1.1306 - val_accuracy: 0.6040\n",
      "Epoch 19/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1646 - accuracy: 0.5851\n",
      "Epoch 19: val_accuracy improved from 0.61490 to 0.64500, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.1646 - accuracy: 0.5851 - val_loss: 1.0083 - val_accuracy: 0.6450\n",
      "Epoch 20/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1417 - accuracy: 0.5951\n",
      "Epoch 20: val_accuracy did not improve from 0.64500\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.1417 - accuracy: 0.5951 - val_loss: 1.0500 - val_accuracy: 0.6360\n",
      "Epoch 21/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1344 - accuracy: 0.5980\n",
      "Epoch 21: val_accuracy did not improve from 0.64500\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.1344 - accuracy: 0.5980 - val_loss: 1.0128 - val_accuracy: 0.6406\n",
      "Epoch 22/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1203 - accuracy: 0.6036\n",
      "Epoch 22: val_accuracy did not improve from 0.64500\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.1203 - accuracy: 0.6036 - val_loss: 1.0275 - val_accuracy: 0.6316\n",
      "Epoch 23/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1090 - accuracy: 0.6086\n",
      "Epoch 23: val_accuracy improved from 0.64500 to 0.64650, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.1090 - accuracy: 0.6086 - val_loss: 1.0114 - val_accuracy: 0.6465\n",
      "Epoch 24/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0925 - accuracy: 0.6102\n",
      "Epoch 24: val_accuracy did not improve from 0.64650\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.0925 - accuracy: 0.6102 - val_loss: 1.0395 - val_accuracy: 0.6367\n",
      "Epoch 25/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0821 - accuracy: 0.6166\n",
      "Epoch 25: val_accuracy improved from 0.64650 to 0.65340, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.0821 - accuracy: 0.6166 - val_loss: 0.9826 - val_accuracy: 0.6534\n",
      "Epoch 26/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0677 - accuracy: 0.6214\n",
      "Epoch 26: val_accuracy improved from 0.65340 to 0.65380, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.0677 - accuracy: 0.6214 - val_loss: 0.9997 - val_accuracy: 0.6538\n",
      "Epoch 27/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0587 - accuracy: 0.6257\n",
      "Epoch 27: val_accuracy improved from 0.65380 to 0.68280, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.0587 - accuracy: 0.6257 - val_loss: 0.8983 - val_accuracy: 0.6828\n",
      "Epoch 28/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0488 - accuracy: 0.6287\n",
      "Epoch 28: val_accuracy did not improve from 0.68280\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.0488 - accuracy: 0.6287 - val_loss: 0.9317 - val_accuracy: 0.6759\n",
      "Epoch 29/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0455 - accuracy: 0.6289\n",
      "Epoch 29: val_accuracy improved from 0.68280 to 0.68290, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.0455 - accuracy: 0.6289 - val_loss: 0.9070 - val_accuracy: 0.6829\n",
      "Epoch 30/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0269 - accuracy: 0.6396\n",
      "Epoch 30: val_accuracy did not improve from 0.68290\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.0269 - accuracy: 0.6396 - val_loss: 0.9334 - val_accuracy: 0.6750\n",
      "Epoch 31/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0154 - accuracy: 0.6425\n",
      "Epoch 31: val_accuracy improved from 0.68290 to 0.68640, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.0154 - accuracy: 0.6425 - val_loss: 0.8936 - val_accuracy: 0.6864\n",
      "Epoch 32/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.6467\n",
      "Epoch 32: val_accuracy did not improve from 0.68640\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.0049 - accuracy: 0.6467 - val_loss: 0.9038 - val_accuracy: 0.6819\n",
      "Epoch 33/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9983 - accuracy: 0.6466\n",
      "Epoch 33: val_accuracy did not improve from 0.68640\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 0.9983 - accuracy: 0.6466 - val_loss: 0.9055 - val_accuracy: 0.6832\n",
      "Epoch 34/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9911 - accuracy: 0.6508\n",
      "Epoch 34: val_accuracy improved from 0.68640 to 0.69250, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 0.9911 - accuracy: 0.6508 - val_loss: 0.8811 - val_accuracy: 0.6925\n",
      "Epoch 35/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9824 - accuracy: 0.6537\n",
      "Epoch 35: val_accuracy did not improve from 0.69250\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 0.9824 - accuracy: 0.6537 - val_loss: 0.8996 - val_accuracy: 0.6840\n",
      "Epoch 36/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9781 - accuracy: 0.6547\n",
      "Epoch 36: val_accuracy improved from 0.69250 to 0.71060, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 0.9781 - accuracy: 0.6547 - val_loss: 0.8295 - val_accuracy: 0.7106\n",
      "Epoch 37/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9663 - accuracy: 0.6575\n",
      "Epoch 37: val_accuracy did not improve from 0.71060\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 0.9663 - accuracy: 0.6575 - val_loss: 0.8600 - val_accuracy: 0.6976\n",
      "Epoch 38/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9547 - accuracy: 0.6615\n",
      "Epoch 38: val_accuracy did not improve from 0.71060\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 0.9547 - accuracy: 0.6615 - val_loss: 0.8581 - val_accuracy: 0.7019\n",
      "Epoch 39/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9469 - accuracy: 0.6629\n",
      "Epoch 39: val_accuracy did not improve from 0.71060\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 0.9469 - accuracy: 0.6629 - val_loss: 0.8751 - val_accuracy: 0.6997\n",
      "Epoch 40/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9470 - accuracy: 0.6645\n",
      "Epoch 40: val_accuracy improved from 0.71060 to 0.72210, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 0.9470 - accuracy: 0.6645 - val_loss: 0.8027 - val_accuracy: 0.7221\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.8027 - accuracy: 0.7221\n",
      "COMBINATION BEST ACCURACY:  0.722100019454956\n",
      "\n",
      "COMBINATION: filter_size=3, dropout_rate=0.35, learning_rate=0.01\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3833 - accuracy: 0.0998\n",
      "Epoch 1: val_accuracy improved from -inf to 0.09730, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 141ms/step - loss: 2.3833 - accuracy: 0.0998 - val_loss: 2.3035 - val_accuracy: 0.0973\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3032 - accuracy: 0.1007\n",
      "Epoch 2: val_accuracy improved from 0.09730 to 0.10170, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 2.3032 - accuracy: 0.1007 - val_loss: 2.3031 - val_accuracy: 0.1017\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3034 - accuracy: 0.0977\n",
      "Epoch 3: val_accuracy improved from 0.10170 to 0.10230, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 2.3034 - accuracy: 0.0977 - val_loss: 2.3027 - val_accuracy: 0.1023\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.0982\n",
      "Epoch 4: val_accuracy did not improve from 0.10230\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 2.3033 - accuracy: 0.0982 - val_loss: 2.3032 - val_accuracy: 0.0994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3032 - accuracy: 0.0997\n",
      "Epoch 5: val_accuracy did not improve from 0.10230\n",
      "312/312 [==============================] - 43s 138ms/step - loss: 2.3032 - accuracy: 0.0997 - val_loss: 2.3033 - val_accuracy: 0.1017\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.1017\n",
      "Epoch 6: val_accuracy did not improve from 0.10230\n",
      "312/312 [==============================] - 43s 138ms/step - loss: 2.3033 - accuracy: 0.1017 - val_loss: 2.3036 - val_accuracy: 0.0973\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3032 - accuracy: 0.1009\n",
      "Epoch 7: val_accuracy did not improve from 0.10230\n",
      "312/312 [==============================] - 43s 137ms/step - loss: 2.3032 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.1015\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.1003\n",
      "Epoch 8: val_accuracy did not improve from 0.10230\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "312/312 [==============================] - 43s 137ms/step - loss: 2.3033 - accuracy: 0.1003 - val_loss: 2.3037 - val_accuracy: 0.1015\n",
      "Epoch 8: early stopping\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 2.3027 - accuracy: 0.1023\n",
      "COMBINATION BEST ACCURACY:  0.1023000031709671\n",
      "\n",
      "COMBINATION: filter_size=3, dropout_rate=0.35, learning_rate=0.001\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.8727 - accuracy: 0.3085\n",
      "Epoch 1: val_accuracy improved from -inf to 0.45310, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 140ms/step - loss: 1.8727 - accuracy: 0.3085 - val_loss: 1.5229 - val_accuracy: 0.4531\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5455 - accuracy: 0.4377\n",
      "Epoch 2: val_accuracy improved from 0.45310 to 0.48380, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.5455 - accuracy: 0.4377 - val_loss: 1.4653 - val_accuracy: 0.4838\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3952 - accuracy: 0.4942\n",
      "Epoch 3: val_accuracy improved from 0.48380 to 0.49540, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.3952 - accuracy: 0.4942 - val_loss: 1.4490 - val_accuracy: 0.4954\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2920 - accuracy: 0.5355\n",
      "Epoch 4: val_accuracy improved from 0.49540 to 0.58720, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.2920 - accuracy: 0.5355 - val_loss: 1.1798 - val_accuracy: 0.5872\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2287 - accuracy: 0.5606\n",
      "Epoch 5: val_accuracy improved from 0.58720 to 0.63560, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.2287 - accuracy: 0.5606 - val_loss: 1.0108 - val_accuracy: 0.6356\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1583 - accuracy: 0.5868\n",
      "Epoch 6: val_accuracy did not improve from 0.63560\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.1583 - accuracy: 0.5868 - val_loss: 1.2091 - val_accuracy: 0.5852\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1186 - accuracy: 0.6016\n",
      "Epoch 7: val_accuracy improved from 0.63560 to 0.66110, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.1186 - accuracy: 0.6016 - val_loss: 0.9435 - val_accuracy: 0.6611\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0735 - accuracy: 0.6180\n",
      "Epoch 8: val_accuracy improved from 0.66110 to 0.67810, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 46s 146ms/step - loss: 1.0735 - accuracy: 0.6180 - val_loss: 0.9121 - val_accuracy: 0.6781\n",
      "Epoch 9/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0351 - accuracy: 0.6350\n",
      "Epoch 9: val_accuracy did not improve from 0.67810\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.0351 - accuracy: 0.6350 - val_loss: 0.9385 - val_accuracy: 0.6697\n",
      "Epoch 10/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0115 - accuracy: 0.6424\n",
      "Epoch 10: val_accuracy did not improve from 0.67810\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 1.0115 - accuracy: 0.6424 - val_loss: 0.9278 - val_accuracy: 0.6768\n",
      "Epoch 11/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9823 - accuracy: 0.6543\n",
      "Epoch 11: val_accuracy did not improve from 0.67810\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 0.9823 - accuracy: 0.6543 - val_loss: 0.9819 - val_accuracy: 0.6632\n",
      "Epoch 12/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9615 - accuracy: 0.6612\n",
      "Epoch 12: val_accuracy improved from 0.67810 to 0.68880, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 0.9615 - accuracy: 0.6612 - val_loss: 0.9069 - val_accuracy: 0.6888\n",
      "Epoch 13/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9353 - accuracy: 0.6690\n",
      "Epoch 13: val_accuracy improved from 0.68880 to 0.72460, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 0.9353 - accuracy: 0.6690 - val_loss: 0.7911 - val_accuracy: 0.7246\n",
      "Epoch 14/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9278 - accuracy: 0.6725\n",
      "Epoch 14: val_accuracy did not improve from 0.72460\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 0.9278 - accuracy: 0.6725 - val_loss: 0.9040 - val_accuracy: 0.6899\n",
      "Epoch 15/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9161 - accuracy: 0.6771\n",
      "Epoch 15: val_accuracy did not improve from 0.72460\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 0.9161 - accuracy: 0.6771 - val_loss: 0.7998 - val_accuracy: 0.7203\n",
      "Epoch 16/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8949 - accuracy: 0.6890\n",
      "Epoch 16: val_accuracy did not improve from 0.72460\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 0.8949 - accuracy: 0.6890 - val_loss: 0.8317 - val_accuracy: 0.7154\n",
      "Epoch 17/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8841 - accuracy: 0.6884\n",
      "Epoch 17: val_accuracy did not improve from 0.72460\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 0.8841 - accuracy: 0.6884 - val_loss: 0.8716 - val_accuracy: 0.7139\n",
      "Epoch 18/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8678 - accuracy: 0.6931\n",
      "Epoch 18: val_accuracy did not improve from 0.72460\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 0.8678 - accuracy: 0.6931 - val_loss: 0.8436 - val_accuracy: 0.7061\n",
      "Epoch 18: early stopping\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.7911 - accuracy: 0.7246\n",
      "COMBINATION BEST ACCURACY:  0.7246000170707703\n",
      "\n",
      "COMBINATION: filter_size=3, dropout_rate=0.35, learning_rate=0.0001\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.9863 - accuracy: 0.2693\n",
      "Epoch 1: val_accuracy improved from -inf to 0.39020, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 142ms/step - loss: 1.9863 - accuracy: 0.2693 - val_loss: 1.7153 - val_accuracy: 0.3902\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.7515 - accuracy: 0.3580\n",
      "Epoch 2: val_accuracy improved from 0.39020 to 0.41550, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.7515 - accuracy: 0.3580 - val_loss: 1.6273 - val_accuracy: 0.4155\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.6706 - accuracy: 0.3855\n",
      "Epoch 3: val_accuracy improved from 0.41550 to 0.45120, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 144ms/step - loss: 1.6706 - accuracy: 0.3855 - val_loss: 1.5367 - val_accuracy: 0.4512\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.6072 - accuracy: 0.4120\n",
      "Epoch 4: val_accuracy improved from 0.45120 to 0.48400, saving model to cnn_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 44s 142ms/step - loss: 1.6072 - accuracy: 0.4120 - val_loss: 1.4316 - val_accuracy: 0.4840\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5594 - accuracy: 0.4336\n",
      "Epoch 5: val_accuracy did not improve from 0.48400\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.5594 - accuracy: 0.4336 - val_loss: 1.4382 - val_accuracy: 0.4824\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5203 - accuracy: 0.4477\n",
      "Epoch 6: val_accuracy did not improve from 0.48400\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.5203 - accuracy: 0.4477 - val_loss: 1.4352 - val_accuracy: 0.4754\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4760 - accuracy: 0.4657\n",
      "Epoch 7: val_accuracy improved from 0.48400 to 0.49200, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 1.4760 - accuracy: 0.4657 - val_loss: 1.4142 - val_accuracy: 0.4920\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4437 - accuracy: 0.4785\n",
      "Epoch 8: val_accuracy improved from 0.49200 to 0.50970, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.4437 - accuracy: 0.4785 - val_loss: 1.3365 - val_accuracy: 0.5097\n",
      "Epoch 9/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4173 - accuracy: 0.4886\n",
      "Epoch 9: val_accuracy improved from 0.50970 to 0.53570, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.4173 - accuracy: 0.4886 - val_loss: 1.2790 - val_accuracy: 0.5357\n",
      "Epoch 10/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3785 - accuracy: 0.5031\n",
      "Epoch 10: val_accuracy improved from 0.53570 to 0.54160, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 1.3785 - accuracy: 0.5031 - val_loss: 1.2804 - val_accuracy: 0.5416\n",
      "Epoch 11/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3596 - accuracy: 0.5116\n",
      "Epoch 11: val_accuracy improved from 0.54160 to 0.55820, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.3596 - accuracy: 0.5116 - val_loss: 1.2447 - val_accuracy: 0.5582\n",
      "Epoch 12/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3284 - accuracy: 0.5238\n",
      "Epoch 12: val_accuracy improved from 0.55820 to 0.57660, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 1.3284 - accuracy: 0.5238 - val_loss: 1.1736 - val_accuracy: 0.5766\n",
      "Epoch 13/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3110 - accuracy: 0.5280\n",
      "Epoch 13: val_accuracy did not improve from 0.57660\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 1.3110 - accuracy: 0.5280 - val_loss: 1.2209 - val_accuracy: 0.5679\n",
      "Epoch 14/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2954 - accuracy: 0.5373\n",
      "Epoch 14: val_accuracy improved from 0.57660 to 0.59700, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 1.2954 - accuracy: 0.5373 - val_loss: 1.1387 - val_accuracy: 0.5970\n",
      "Epoch 15/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2752 - accuracy: 0.5426\n",
      "Epoch 15: val_accuracy did not improve from 0.59700\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.2752 - accuracy: 0.5426 - val_loss: 1.1933 - val_accuracy: 0.5821\n",
      "Epoch 16/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2587 - accuracy: 0.5502\n",
      "Epoch 16: val_accuracy improved from 0.59700 to 0.59810, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.2587 - accuracy: 0.5502 - val_loss: 1.1261 - val_accuracy: 0.5981\n",
      "Epoch 17/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2404 - accuracy: 0.5558\n",
      "Epoch 17: val_accuracy did not improve from 0.59810\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.2404 - accuracy: 0.5558 - val_loss: 1.1763 - val_accuracy: 0.5844\n",
      "Epoch 18/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2238 - accuracy: 0.5660\n",
      "Epoch 18: val_accuracy improved from 0.59810 to 0.59840, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.2238 - accuracy: 0.5660 - val_loss: 1.1483 - val_accuracy: 0.5984\n",
      "Epoch 19/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2047 - accuracy: 0.5700\n",
      "Epoch 19: val_accuracy improved from 0.59840 to 0.61250, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.2047 - accuracy: 0.5700 - val_loss: 1.0866 - val_accuracy: 0.6125\n",
      "Epoch 20/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1918 - accuracy: 0.5766\n",
      "Epoch 20: val_accuracy did not improve from 0.61250\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.1918 - accuracy: 0.5766 - val_loss: 1.1139 - val_accuracy: 0.6091\n",
      "Epoch 21/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1779 - accuracy: 0.5808\n",
      "Epoch 21: val_accuracy did not improve from 0.61250\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.1779 - accuracy: 0.5808 - val_loss: 1.1514 - val_accuracy: 0.5956\n",
      "Epoch 22/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1638 - accuracy: 0.5833\n",
      "Epoch 22: val_accuracy improved from 0.61250 to 0.61490, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.1638 - accuracy: 0.5833 - val_loss: 1.0882 - val_accuracy: 0.6149\n",
      "Epoch 23/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1628 - accuracy: 0.5902\n",
      "Epoch 23: val_accuracy improved from 0.61490 to 0.62280, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.1628 - accuracy: 0.5902 - val_loss: 1.0761 - val_accuracy: 0.6228\n",
      "Epoch 24/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1440 - accuracy: 0.5945\n",
      "Epoch 24: val_accuracy did not improve from 0.62280\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.1440 - accuracy: 0.5945 - val_loss: 1.1639 - val_accuracy: 0.6001\n",
      "Epoch 25/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1352 - accuracy: 0.5956\n",
      "Epoch 25: val_accuracy did not improve from 0.62280\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.1352 - accuracy: 0.5956 - val_loss: 1.0923 - val_accuracy: 0.6151\n",
      "Epoch 26/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1238 - accuracy: 0.6001\n",
      "Epoch 26: val_accuracy improved from 0.62280 to 0.62420, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.1238 - accuracy: 0.6001 - val_loss: 1.0738 - val_accuracy: 0.6242\n",
      "Epoch 27/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1094 - accuracy: 0.6026\n",
      "Epoch 27: val_accuracy did not improve from 0.62420\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.1094 - accuracy: 0.6026 - val_loss: 1.1052 - val_accuracy: 0.6126\n",
      "Epoch 28/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1004 - accuracy: 0.6117\n",
      "Epoch 28: val_accuracy improved from 0.62420 to 0.64920, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.1004 - accuracy: 0.6117 - val_loss: 0.9911 - val_accuracy: 0.6492\n",
      "Epoch 29/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0898 - accuracy: 0.6134\n",
      "Epoch 29: val_accuracy did not improve from 0.64920\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.0898 - accuracy: 0.6134 - val_loss: 1.0060 - val_accuracy: 0.6489\n",
      "Epoch 30/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0827 - accuracy: 0.6157\n",
      "Epoch 30: val_accuracy improved from 0.64920 to 0.65120, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.0827 - accuracy: 0.6157 - val_loss: 1.0050 - val_accuracy: 0.6512\n",
      "Epoch 31/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0717 - accuracy: 0.6215\n",
      "Epoch 31: val_accuracy improved from 0.65120 to 0.65510, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.0717 - accuracy: 0.6215 - val_loss: 0.9742 - val_accuracy: 0.6551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0650 - accuracy: 0.6244\n",
      "Epoch 32: val_accuracy did not improve from 0.65510\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.0650 - accuracy: 0.6244 - val_loss: 1.0074 - val_accuracy: 0.6458\n",
      "Epoch 33/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0543 - accuracy: 0.6253\n",
      "Epoch 33: val_accuracy did not improve from 0.65510\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.0543 - accuracy: 0.6253 - val_loss: 0.9999 - val_accuracy: 0.6530\n",
      "Epoch 34/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0408 - accuracy: 0.6331\n",
      "Epoch 34: val_accuracy improved from 0.65510 to 0.67430, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 1.0408 - accuracy: 0.6331 - val_loss: 0.9265 - val_accuracy: 0.6743\n",
      "Epoch 35/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0395 - accuracy: 0.6327\n",
      "Epoch 35: val_accuracy did not improve from 0.67430\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.0395 - accuracy: 0.6327 - val_loss: 0.9286 - val_accuracy: 0.6702\n",
      "Epoch 36/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0264 - accuracy: 0.6391\n",
      "Epoch 36: val_accuracy did not improve from 0.67430\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.0264 - accuracy: 0.6391 - val_loss: 1.0173 - val_accuracy: 0.6519\n",
      "Epoch 37/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0233 - accuracy: 0.6382\n",
      "Epoch 37: val_accuracy did not improve from 0.67430\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.0233 - accuracy: 0.6382 - val_loss: 1.0307 - val_accuracy: 0.6461\n",
      "Epoch 38/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0049 - accuracy: 0.6428\n",
      "Epoch 38: val_accuracy did not improve from 0.67430\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.0049 - accuracy: 0.6428 - val_loss: 0.9768 - val_accuracy: 0.6615\n",
      "Epoch 39/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0060 - accuracy: 0.6447\n",
      "Epoch 39: val_accuracy improved from 0.67430 to 0.67600, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.0060 - accuracy: 0.6447 - val_loss: 0.9356 - val_accuracy: 0.6760\n",
      "Epoch 40/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9952 - accuracy: 0.6488\n",
      "Epoch 40: val_accuracy did not improve from 0.67600\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 0.9952 - accuracy: 0.6488 - val_loss: 1.0341 - val_accuracy: 0.6481\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.9356 - accuracy: 0.6760\n",
      "COMBINATION BEST ACCURACY:  0.6759999990463257\n",
      "\n",
      "COMBINATION: filter_size=3, dropout_rate=0.5, learning_rate=0.01\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3330 - accuracy: 0.1020\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10170, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 2.3330 - accuracy: 0.1020 - val_loss: 2.3037 - val_accuracy: 0.1017\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3034 - accuracy: 0.1021\n",
      "Epoch 2: val_accuracy did not improve from 0.10170\n",
      "312/312 [==============================] - 43s 137ms/step - loss: 2.3034 - accuracy: 0.1021 - val_loss: 2.3034 - val_accuracy: 0.0933\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3032 - accuracy: 0.1011\n",
      "Epoch 3: val_accuracy did not improve from 0.10170\n",
      "312/312 [==============================] - 43s 138ms/step - loss: 2.3032 - accuracy: 0.1011 - val_loss: 2.3040 - val_accuracy: 0.0973\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3034 - accuracy: 0.0985\n",
      "Epoch 4: val_accuracy did not improve from 0.10170\n",
      "312/312 [==============================] - 43s 138ms/step - loss: 2.3034 - accuracy: 0.0985 - val_loss: 2.3029 - val_accuracy: 0.0979\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3034 - accuracy: 0.1005\n",
      "Epoch 5: val_accuracy improved from 0.10170 to 0.10300, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 2.3034 - accuracy: 0.1005 - val_loss: 2.3026 - val_accuracy: 0.1030\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3034 - accuracy: 0.0962\n",
      "Epoch 6: val_accuracy did not improve from 0.10300\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 2.3034 - accuracy: 0.0962 - val_loss: 2.3039 - val_accuracy: 0.0996\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3034 - accuracy: 0.1004\n",
      "Epoch 7: val_accuracy did not improve from 0.10300\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 2.3034 - accuracy: 0.1004 - val_loss: 2.3040 - val_accuracy: 0.0933\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.0978\n",
      "Epoch 8: val_accuracy did not improve from 0.10300\n",
      "312/312 [==============================] - 43s 138ms/step - loss: 2.3033 - accuracy: 0.0978 - val_loss: 2.3035 - val_accuracy: 0.0979\n",
      "Epoch 9/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.1001\n",
      "Epoch 9: val_accuracy did not improve from 0.10300\n",
      "312/312 [==============================] - 43s 138ms/step - loss: 2.3033 - accuracy: 0.1001 - val_loss: 2.3037 - val_accuracy: 0.0973\n",
      "Epoch 10/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.0976\n",
      "Epoch 10: val_accuracy improved from 0.10300 to 0.10400, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 2.3033 - accuracy: 0.0976 - val_loss: 2.3033 - val_accuracy: 0.1040\n",
      "Epoch 11/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.1006\n",
      "Epoch 11: val_accuracy did not improve from 0.10400\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 2.3033 - accuracy: 0.1006 - val_loss: 2.3028 - val_accuracy: 0.1017\n",
      "Epoch 12/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.0982\n",
      "Epoch 12: val_accuracy did not improve from 0.10400\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 2.3033 - accuracy: 0.0982 - val_loss: 2.3038 - val_accuracy: 0.0994\n",
      "Epoch 13/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3031 - accuracy: 0.1019\n",
      "Epoch 13: val_accuracy did not improve from 0.10400\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 2.3031 - accuracy: 0.1019 - val_loss: 2.3035 - val_accuracy: 0.1023\n",
      "Epoch 14/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.0975\n",
      "Epoch 14: val_accuracy did not improve from 0.10400\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 2.3033 - accuracy: 0.0975 - val_loss: 2.3030 - val_accuracy: 0.0979\n",
      "Epoch 15/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.0991\n",
      "Epoch 15: val_accuracy did not improve from 0.10400\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 2.3033 - accuracy: 0.0991 - val_loss: 2.3036 - val_accuracy: 0.0933\n",
      "Epoch 15: early stopping\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 2.3033 - accuracy: 0.1040\n",
      "COMBINATION BEST ACCURACY:  0.10400000214576721\n",
      "\n",
      "COMBINATION: filter_size=3, dropout_rate=0.5, learning_rate=0.001\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.8735 - accuracy: 0.3059\n",
      "Epoch 1: val_accuracy improved from -inf to 0.46160, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 141ms/step - loss: 1.8735 - accuracy: 0.3059 - val_loss: 1.4971 - val_accuracy: 0.4616\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5950 - accuracy: 0.4131\n",
      "Epoch 2: val_accuracy improved from 0.46160 to 0.48410, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.5950 - accuracy: 0.4131 - val_loss: 1.4328 - val_accuracy: 0.4841\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4703 - accuracy: 0.4659\n",
      "Epoch 3: val_accuracy improved from 0.48410 to 0.50180, saving model to cnn_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 44s 141ms/step - loss: 1.4703 - accuracy: 0.4659 - val_loss: 1.4344 - val_accuracy: 0.5018\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3917 - accuracy: 0.4961\n",
      "Epoch 4: val_accuracy improved from 0.50180 to 0.53170, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 1.3917 - accuracy: 0.4961 - val_loss: 1.3482 - val_accuracy: 0.5317\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3258 - accuracy: 0.5186\n",
      "Epoch 5: val_accuracy improved from 0.53170 to 0.55540, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.3258 - accuracy: 0.5186 - val_loss: 1.2516 - val_accuracy: 0.5554\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2672 - accuracy: 0.5408\n",
      "Epoch 6: val_accuracy did not improve from 0.55540\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.2672 - accuracy: 0.5408 - val_loss: 1.3115 - val_accuracy: 0.5514\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2253 - accuracy: 0.5602\n",
      "Epoch 7: val_accuracy improved from 0.55540 to 0.59370, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.2253 - accuracy: 0.5602 - val_loss: 1.1692 - val_accuracy: 0.5937\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2010 - accuracy: 0.5720\n",
      "Epoch 8: val_accuracy improved from 0.59370 to 0.62690, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.2010 - accuracy: 0.5720 - val_loss: 1.0671 - val_accuracy: 0.6269\n",
      "Epoch 9/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1629 - accuracy: 0.5878\n",
      "Epoch 9: val_accuracy improved from 0.62690 to 0.65530, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 1.1629 - accuracy: 0.5878 - val_loss: 0.9876 - val_accuracy: 0.6553\n",
      "Epoch 10/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1248 - accuracy: 0.5975\n",
      "Epoch 10: val_accuracy did not improve from 0.65530\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.1248 - accuracy: 0.5975 - val_loss: 1.1075 - val_accuracy: 0.6180\n",
      "Epoch 11/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1082 - accuracy: 0.6070\n",
      "Epoch 11: val_accuracy did not improve from 0.65530\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 1.1082 - accuracy: 0.6070 - val_loss: 1.0205 - val_accuracy: 0.6468\n",
      "Epoch 12/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0829 - accuracy: 0.6158\n",
      "Epoch 12: val_accuracy did not improve from 0.65530\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.0829 - accuracy: 0.6158 - val_loss: 1.1295 - val_accuracy: 0.6207\n",
      "Epoch 13/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0601 - accuracy: 0.6273\n",
      "Epoch 13: val_accuracy improved from 0.65530 to 0.65680, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.0601 - accuracy: 0.6273 - val_loss: 0.9929 - val_accuracy: 0.6568\n",
      "Epoch 14/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0444 - accuracy: 0.6278\n",
      "Epoch 14: val_accuracy improved from 0.65680 to 0.67980, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.0444 - accuracy: 0.6278 - val_loss: 0.9395 - val_accuracy: 0.6798\n",
      "Epoch 15/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0336 - accuracy: 0.6334\n",
      "Epoch 15: val_accuracy did not improve from 0.67980\n",
      "312/312 [==============================] - 43s 139ms/step - loss: 1.0336 - accuracy: 0.6334 - val_loss: 0.9412 - val_accuracy: 0.6719\n",
      "Epoch 16/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0208 - accuracy: 0.6392\n",
      "Epoch 16: val_accuracy did not improve from 0.67980\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.0208 - accuracy: 0.6392 - val_loss: 0.9905 - val_accuracy: 0.6633\n",
      "Epoch 17/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9948 - accuracy: 0.6450\n",
      "Epoch 17: val_accuracy did not improve from 0.67980\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 0.9948 - accuracy: 0.6450 - val_loss: 0.9469 - val_accuracy: 0.6764\n",
      "Epoch 18/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9889 - accuracy: 0.6523\n",
      "Epoch 18: val_accuracy did not improve from 0.67980\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 0.9889 - accuracy: 0.6523 - val_loss: 0.9623 - val_accuracy: 0.6704\n",
      "Epoch 19/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9805 - accuracy: 0.6560\n",
      "Epoch 19: val_accuracy did not improve from 0.67980\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 0.9805 - accuracy: 0.6560 - val_loss: 1.0325 - val_accuracy: 0.6534\n",
      "Epoch 19: early stopping\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.9395 - accuracy: 0.6798\n",
      "COMBINATION BEST ACCURACY:  0.6797999739646912\n",
      "\n",
      "COMBINATION: filter_size=3, dropout_rate=0.5, learning_rate=0.0001\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.0913 - accuracy: 0.2229\n",
      "Epoch 1: val_accuracy improved from -inf to 0.35790, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 142ms/step - loss: 2.0913 - accuracy: 0.2229 - val_loss: 1.8263 - val_accuracy: 0.3579\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.8430 - accuracy: 0.3251\n",
      "Epoch 2: val_accuracy improved from 0.35790 to 0.39760, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 142ms/step - loss: 1.8430 - accuracy: 0.3251 - val_loss: 1.6706 - val_accuracy: 0.3976\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.7526 - accuracy: 0.3581\n",
      "Epoch 3: val_accuracy improved from 0.39760 to 0.41220, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 144ms/step - loss: 1.7526 - accuracy: 0.3581 - val_loss: 1.6042 - val_accuracy: 0.4122\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.6870 - accuracy: 0.3821\n",
      "Epoch 4: val_accuracy improved from 0.41220 to 0.44950, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.6870 - accuracy: 0.3821 - val_loss: 1.5117 - val_accuracy: 0.4495\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.6342 - accuracy: 0.4029\n",
      "Epoch 5: val_accuracy improved from 0.44950 to 0.44990, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 144ms/step - loss: 1.6342 - accuracy: 0.4029 - val_loss: 1.4878 - val_accuracy: 0.4499\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5964 - accuracy: 0.4183\n",
      "Epoch 6: val_accuracy improved from 0.44990 to 0.46200, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.5964 - accuracy: 0.4183 - val_loss: 1.4678 - val_accuracy: 0.4620\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5681 - accuracy: 0.4310\n",
      "Epoch 7: val_accuracy did not improve from 0.46200\n",
      "312/312 [==============================] - 45s 145ms/step - loss: 1.5681 - accuracy: 0.4310 - val_loss: 1.4821 - val_accuracy: 0.4559\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5326 - accuracy: 0.4408\n",
      "Epoch 8: val_accuracy did not improve from 0.46200\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 1.5326 - accuracy: 0.4408 - val_loss: 1.5084 - val_accuracy: 0.4502\n",
      "Epoch 9/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5214 - accuracy: 0.4478\n",
      "Epoch 9: val_accuracy improved from 0.46200 to 0.48540, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 1.5214 - accuracy: 0.4478 - val_loss: 1.4329 - val_accuracy: 0.4854\n",
      "Epoch 10/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4910 - accuracy: 0.4572\n",
      "Epoch 10: val_accuracy did not improve from 0.48540\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 1.4910 - accuracy: 0.4572 - val_loss: 1.4767 - val_accuracy: 0.4752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4669 - accuracy: 0.4707\n",
      "Epoch 11: val_accuracy improved from 0.48540 to 0.49860, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.4669 - accuracy: 0.4707 - val_loss: 1.3862 - val_accuracy: 0.4986\n",
      "Epoch 12/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4389 - accuracy: 0.4808\n",
      "Epoch 12: val_accuracy improved from 0.49860 to 0.50970, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.4389 - accuracy: 0.4808 - val_loss: 1.3593 - val_accuracy: 0.5097\n",
      "Epoch 13/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4224 - accuracy: 0.4876\n",
      "Epoch 13: val_accuracy did not improve from 0.50970\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.4224 - accuracy: 0.4876 - val_loss: 1.4385 - val_accuracy: 0.4869\n",
      "Epoch 14/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4098 - accuracy: 0.4948\n",
      "Epoch 14: val_accuracy did not improve from 0.50970\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.4098 - accuracy: 0.4948 - val_loss: 1.4314 - val_accuracy: 0.4916\n",
      "Epoch 15/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3870 - accuracy: 0.4968\n",
      "Epoch 15: val_accuracy improved from 0.50970 to 0.52180, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.3870 - accuracy: 0.4968 - val_loss: 1.3400 - val_accuracy: 0.5218\n",
      "Epoch 16/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3665 - accuracy: 0.5093\n",
      "Epoch 16: val_accuracy did not improve from 0.52180\n",
      "312/312 [==============================] - 44s 139ms/step - loss: 1.3665 - accuracy: 0.5093 - val_loss: 1.4290 - val_accuracy: 0.5012\n",
      "Epoch 17/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3477 - accuracy: 0.5141\n",
      "Epoch 17: val_accuracy improved from 0.52180 to 0.54340, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.3477 - accuracy: 0.5141 - val_loss: 1.2930 - val_accuracy: 0.5434\n",
      "Epoch 18/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3395 - accuracy: 0.5203\n",
      "Epoch 18: val_accuracy improved from 0.54340 to 0.55560, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.3395 - accuracy: 0.5203 - val_loss: 1.2457 - val_accuracy: 0.5556\n",
      "Epoch 19/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3240 - accuracy: 0.5242\n",
      "Epoch 19: val_accuracy did not improve from 0.55560\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.3240 - accuracy: 0.5242 - val_loss: 1.3440 - val_accuracy: 0.5300\n",
      "Epoch 20/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3091 - accuracy: 0.5325\n",
      "Epoch 20: val_accuracy did not improve from 0.55560\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.3091 - accuracy: 0.5325 - val_loss: 1.3339 - val_accuracy: 0.5336\n",
      "Epoch 21/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2963 - accuracy: 0.5342\n",
      "Epoch 21: val_accuracy improved from 0.55560 to 0.55720, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.2963 - accuracy: 0.5342 - val_loss: 1.2644 - val_accuracy: 0.5572\n",
      "Epoch 22/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2854 - accuracy: 0.5406\n",
      "Epoch 22: val_accuracy did not improve from 0.55720\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.2854 - accuracy: 0.5406 - val_loss: 1.3277 - val_accuracy: 0.5423\n",
      "Epoch 23/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2733 - accuracy: 0.5440\n",
      "Epoch 23: val_accuracy improved from 0.55720 to 0.55860, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.2733 - accuracy: 0.5440 - val_loss: 1.2515 - val_accuracy: 0.5586\n",
      "Epoch 24/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2581 - accuracy: 0.5477\n",
      "Epoch 24: val_accuracy improved from 0.55860 to 0.56910, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.2581 - accuracy: 0.5477 - val_loss: 1.2270 - val_accuracy: 0.5691\n",
      "Epoch 25/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2484 - accuracy: 0.5555\n",
      "Epoch 25: val_accuracy improved from 0.56910 to 0.56930, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.2484 - accuracy: 0.5555 - val_loss: 1.2310 - val_accuracy: 0.5693\n",
      "Epoch 26/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2403 - accuracy: 0.5533\n",
      "Epoch 26: val_accuracy did not improve from 0.56930\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.2403 - accuracy: 0.5533 - val_loss: 1.3050 - val_accuracy: 0.5496\n",
      "Epoch 27/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2274 - accuracy: 0.5607\n",
      "Epoch 27: val_accuracy improved from 0.56930 to 0.58610, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.2274 - accuracy: 0.5607 - val_loss: 1.1777 - val_accuracy: 0.5861\n",
      "Epoch 28/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2165 - accuracy: 0.5661\n",
      "Epoch 28: val_accuracy improved from 0.58610 to 0.60100, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.2165 - accuracy: 0.5661 - val_loss: 1.1208 - val_accuracy: 0.6010\n",
      "Epoch 29/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2070 - accuracy: 0.5716\n",
      "Epoch 29: val_accuracy did not improve from 0.60100\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.2070 - accuracy: 0.5716 - val_loss: 1.1459 - val_accuracy: 0.5969\n",
      "Epoch 30/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1969 - accuracy: 0.5711\n",
      "Epoch 30: val_accuracy improved from 0.60100 to 0.61370, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.1969 - accuracy: 0.5711 - val_loss: 1.0964 - val_accuracy: 0.6137\n",
      "Epoch 31/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1952 - accuracy: 0.5714\n",
      "Epoch 31: val_accuracy did not improve from 0.61370\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.1952 - accuracy: 0.5714 - val_loss: 1.1553 - val_accuracy: 0.5925\n",
      "Epoch 32/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1767 - accuracy: 0.5794\n",
      "Epoch 32: val_accuracy did not improve from 0.61370\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.1767 - accuracy: 0.5794 - val_loss: 1.1199 - val_accuracy: 0.6024\n",
      "Epoch 33/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1712 - accuracy: 0.5790\n",
      "Epoch 33: val_accuracy improved from 0.61370 to 0.61770, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 48s 154ms/step - loss: 1.1712 - accuracy: 0.5790 - val_loss: 1.0929 - val_accuracy: 0.6177\n",
      "Epoch 34/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1719 - accuracy: 0.5818\n",
      "Epoch 34: val_accuracy improved from 0.61770 to 0.62760, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 45s 143ms/step - loss: 1.1719 - accuracy: 0.5818 - val_loss: 1.0619 - val_accuracy: 0.6276\n",
      "Epoch 35/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1552 - accuracy: 0.5897\n",
      "Epoch 35: val_accuracy did not improve from 0.62760\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.1552 - accuracy: 0.5897 - val_loss: 1.1063 - val_accuracy: 0.6133\n",
      "Epoch 36/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1441 - accuracy: 0.5920\n",
      "Epoch 36: val_accuracy did not improve from 0.62760\n",
      "312/312 [==============================] - 44s 142ms/step - loss: 1.1441 - accuracy: 0.5920 - val_loss: 1.0776 - val_accuracy: 0.6194\n",
      "Epoch 37/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1463 - accuracy: 0.5917\n",
      "Epoch 37: val_accuracy did not improve from 0.62760\n",
      "312/312 [==============================] - 45s 144ms/step - loss: 1.1463 - accuracy: 0.5917 - val_loss: 1.1029 - val_accuracy: 0.6122\n",
      "Epoch 38/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1356 - accuracy: 0.5952\n",
      "Epoch 38: val_accuracy improved from 0.62760 to 0.63600, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 44s 141ms/step - loss: 1.1356 - accuracy: 0.5952 - val_loss: 1.0353 - val_accuracy: 0.6360\n",
      "Epoch 39/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1247 - accuracy: 0.6003\n",
      "Epoch 39: val_accuracy did not improve from 0.63600\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.1247 - accuracy: 0.6003 - val_loss: 1.1091 - val_accuracy: 0.6149\n",
      "Epoch 40/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1150 - accuracy: 0.6032\n",
      "Epoch 40: val_accuracy did not improve from 0.63600\n",
      "312/312 [==============================] - 44s 140ms/step - loss: 1.1150 - accuracy: 0.6032 - val_loss: 1.0593 - val_accuracy: 0.6283\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 1.0353 - accuracy: 0.6360\n",
      "COMBINATION BEST ACCURACY:  0.6359999775886536\n",
      "\n",
      "COMBINATION: filter_size=5, dropout_rate=0.2, learning_rate=0.01\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 4.1891 - accuracy: 0.0994\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10300, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 65s 206ms/step - loss: 4.1891 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.1030\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3034 - accuracy: 0.0984\n",
      "Epoch 2: val_accuracy did not improve from 0.10300\n",
      "312/312 [==============================] - 62s 199ms/step - loss: 2.3034 - accuracy: 0.0984 - val_loss: 2.3032 - val_accuracy: 0.0979\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.0997\n",
      "Epoch 3: val_accuracy did not improve from 0.10300\n",
      "312/312 [==============================] - 63s 200ms/step - loss: 2.3033 - accuracy: 0.0997 - val_loss: 2.3034 - val_accuracy: 0.1023\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.0994\n",
      "Epoch 4: val_accuracy did not improve from 0.10300\n",
      "312/312 [==============================] - 62s 200ms/step - loss: 2.3033 - accuracy: 0.0994 - val_loss: 2.3031 - val_accuracy: 0.0979\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3032 - accuracy: 0.1010\n",
      "Epoch 5: val_accuracy did not improve from 0.10300\n",
      "312/312 [==============================] - 63s 200ms/step - loss: 2.3032 - accuracy: 0.1010 - val_loss: 2.3043 - val_accuracy: 0.0973\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3034 - accuracy: 0.1010\n",
      "Epoch 6: val_accuracy did not improve from 0.10300\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "312/312 [==============================] - 62s 200ms/step - loss: 2.3034 - accuracy: 0.1010 - val_loss: 2.3041 - val_accuracy: 0.0973\n",
      "Epoch 6: early stopping\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 2.3027 - accuracy: 0.1030\n",
      "COMBINATION BEST ACCURACY:  0.10300000011920929\n",
      "\n",
      "COMBINATION: filter_size=5, dropout_rate=0.2, learning_rate=0.001\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.8883 - accuracy: 0.2982\n",
      "Epoch 1: val_accuracy improved from -inf to 0.44590, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 203ms/step - loss: 1.8883 - accuracy: 0.2982 - val_loss: 1.5232 - val_accuracy: 0.4459\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5538 - accuracy: 0.4344\n",
      "Epoch 2: val_accuracy improved from 0.44590 to 0.48960, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.5538 - accuracy: 0.4344 - val_loss: 1.4162 - val_accuracy: 0.4896\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4121 - accuracy: 0.4886\n",
      "Epoch 3: val_accuracy improved from 0.48960 to 0.57430, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.4121 - accuracy: 0.4886 - val_loss: 1.1938 - val_accuracy: 0.5743\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3161 - accuracy: 0.5268\n",
      "Epoch 4: val_accuracy improved from 0.57430 to 0.58780, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 1.3161 - accuracy: 0.5268 - val_loss: 1.1538 - val_accuracy: 0.5878\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2500 - accuracy: 0.5486\n",
      "Epoch 5: val_accuracy improved from 0.58780 to 0.61740, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.2500 - accuracy: 0.5486 - val_loss: 1.0553 - val_accuracy: 0.6174\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1853 - accuracy: 0.5773\n",
      "Epoch 6: val_accuracy improved from 0.61740 to 0.64430, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 1.1853 - accuracy: 0.5773 - val_loss: 1.0158 - val_accuracy: 0.6443\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1306 - accuracy: 0.5979\n",
      "Epoch 7: val_accuracy improved from 0.64430 to 0.64770, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 1.1306 - accuracy: 0.5979 - val_loss: 1.0004 - val_accuracy: 0.6477\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0778 - accuracy: 0.6172\n",
      "Epoch 8: val_accuracy improved from 0.64770 to 0.68190, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.0778 - accuracy: 0.6172 - val_loss: 0.9115 - val_accuracy: 0.6819\n",
      "Epoch 9/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0483 - accuracy: 0.6300\n",
      "Epoch 9: val_accuracy improved from 0.68190 to 0.69100, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.0483 - accuracy: 0.6300 - val_loss: 0.8763 - val_accuracy: 0.6910\n",
      "Epoch 10/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0160 - accuracy: 0.6422\n",
      "Epoch 10: val_accuracy did not improve from 0.69100\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 1.0160 - accuracy: 0.6422 - val_loss: 0.8699 - val_accuracy: 0.6898\n",
      "Epoch 11/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9803 - accuracy: 0.6533\n",
      "Epoch 11: val_accuracy improved from 0.69100 to 0.70250, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.9803 - accuracy: 0.6533 - val_loss: 0.8572 - val_accuracy: 0.7025\n",
      "Epoch 12/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9609 - accuracy: 0.6621\n",
      "Epoch 12: val_accuracy did not improve from 0.70250\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.9609 - accuracy: 0.6621 - val_loss: 0.8715 - val_accuracy: 0.6909\n",
      "Epoch 13/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9423 - accuracy: 0.6705\n",
      "Epoch 13: val_accuracy improved from 0.70250 to 0.72590, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 0.9423 - accuracy: 0.6705 - val_loss: 0.7947 - val_accuracy: 0.7259\n",
      "Epoch 14/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9136 - accuracy: 0.6790\n",
      "Epoch 14: val_accuracy improved from 0.72590 to 0.73590, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 0.9136 - accuracy: 0.6790 - val_loss: 0.7627 - val_accuracy: 0.7359\n",
      "Epoch 15/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8996 - accuracy: 0.6843\n",
      "Epoch 15: val_accuracy did not improve from 0.73590\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 0.8996 - accuracy: 0.6843 - val_loss: 0.7686 - val_accuracy: 0.7356\n",
      "Epoch 16/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8877 - accuracy: 0.6915\n",
      "Epoch 16: val_accuracy improved from 0.73590 to 0.74090, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.8877 - accuracy: 0.6915 - val_loss: 0.7551 - val_accuracy: 0.7409\n",
      "Epoch 17/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8755 - accuracy: 0.6951\n",
      "Epoch 17: val_accuracy did not improve from 0.74090\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 0.8755 - accuracy: 0.6951 - val_loss: 0.8023 - val_accuracy: 0.7192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8523 - accuracy: 0.7013\n",
      "Epoch 18: val_accuracy did not improve from 0.74090\n",
      "312/312 [==============================] - 63s 200ms/step - loss: 0.8523 - accuracy: 0.7013 - val_loss: 0.7550 - val_accuracy: 0.7395\n",
      "Epoch 19/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8453 - accuracy: 0.7020\n",
      "Epoch 19: val_accuracy improved from 0.74090 to 0.75710, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 200ms/step - loss: 0.8453 - accuracy: 0.7020 - val_loss: 0.7048 - val_accuracy: 0.7571\n",
      "Epoch 20/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8367 - accuracy: 0.7072\n",
      "Epoch 20: val_accuracy did not improve from 0.75710\n",
      "312/312 [==============================] - 62s 200ms/step - loss: 0.8367 - accuracy: 0.7072 - val_loss: 0.7427 - val_accuracy: 0.7421\n",
      "Epoch 21/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8291 - accuracy: 0.7102\n",
      "Epoch 21: val_accuracy did not improve from 0.75710\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 0.8291 - accuracy: 0.7102 - val_loss: 0.7660 - val_accuracy: 0.7343\n",
      "Epoch 22/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8163 - accuracy: 0.7126\n",
      "Epoch 22: val_accuracy did not improve from 0.75710\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 0.8163 - accuracy: 0.7126 - val_loss: 0.7284 - val_accuracy: 0.7493\n",
      "Epoch 23/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8106 - accuracy: 0.7166\n",
      "Epoch 23: val_accuracy did not improve from 0.75710\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 0.8106 - accuracy: 0.7166 - val_loss: 0.7897 - val_accuracy: 0.7288\n",
      "Epoch 24/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8075 - accuracy: 0.7173\n",
      "Epoch 24: val_accuracy did not improve from 0.75710\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "312/312 [==============================] - 62s 200ms/step - loss: 0.8075 - accuracy: 0.7173 - val_loss: 0.7133 - val_accuracy: 0.7513\n",
      "Epoch 24: early stopping\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.7048 - accuracy: 0.7571\n",
      "COMBINATION BEST ACCURACY:  0.757099986076355\n",
      "\n",
      "COMBINATION: filter_size=5, dropout_rate=0.2, learning_rate=0.0001\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.9314 - accuracy: 0.2876\n",
      "Epoch 1: val_accuracy improved from -inf to 0.40930, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 65s 204ms/step - loss: 1.9314 - accuracy: 0.2876 - val_loss: 1.6471 - val_accuracy: 0.4093\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.6870 - accuracy: 0.3837\n",
      "Epoch 2: val_accuracy improved from 0.40930 to 0.44200, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 1.6870 - accuracy: 0.3837 - val_loss: 1.5191 - val_accuracy: 0.4420\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5902 - accuracy: 0.4214\n",
      "Epoch 3: val_accuracy improved from 0.44200 to 0.47210, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 206ms/step - loss: 1.5902 - accuracy: 0.4214 - val_loss: 1.4787 - val_accuracy: 0.4721\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5183 - accuracy: 0.4513\n",
      "Epoch 4: val_accuracy improved from 0.47210 to 0.50920, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 203ms/step - loss: 1.5183 - accuracy: 0.4513 - val_loss: 1.3773 - val_accuracy: 0.5092\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4628 - accuracy: 0.4737\n",
      "Epoch 5: val_accuracy improved from 0.50920 to 0.51300, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 1.4628 - accuracy: 0.4737 - val_loss: 1.3321 - val_accuracy: 0.5130\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4110 - accuracy: 0.4936\n",
      "Epoch 6: val_accuracy improved from 0.51300 to 0.54230, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 1.4110 - accuracy: 0.4936 - val_loss: 1.2753 - val_accuracy: 0.5423\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3656 - accuracy: 0.5108\n",
      "Epoch 7: val_accuracy improved from 0.54230 to 0.55780, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 1.3656 - accuracy: 0.5108 - val_loss: 1.2295 - val_accuracy: 0.5578\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3364 - accuracy: 0.5203\n",
      "Epoch 8: val_accuracy improved from 0.55780 to 0.58490, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 1.3364 - accuracy: 0.5203 - val_loss: 1.1653 - val_accuracy: 0.5849\n",
      "Epoch 9/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2944 - accuracy: 0.5374\n",
      "Epoch 9: val_accuracy did not improve from 0.58490\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 1.2944 - accuracy: 0.5374 - val_loss: 1.1560 - val_accuracy: 0.5846\n",
      "Epoch 10/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2657 - accuracy: 0.5474\n",
      "Epoch 10: val_accuracy improved from 0.58490 to 0.60950, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 1.2657 - accuracy: 0.5474 - val_loss: 1.0908 - val_accuracy: 0.6095\n",
      "Epoch 11/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2399 - accuracy: 0.5585\n",
      "Epoch 11: val_accuracy did not improve from 0.60950\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 1.2399 - accuracy: 0.5585 - val_loss: 1.1181 - val_accuracy: 0.6031\n",
      "Epoch 12/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2074 - accuracy: 0.5711\n",
      "Epoch 12: val_accuracy improved from 0.60950 to 0.62930, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 1.2074 - accuracy: 0.5711 - val_loss: 1.0402 - val_accuracy: 0.6293\n",
      "Epoch 13/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1880 - accuracy: 0.5774\n",
      "Epoch 13: val_accuracy improved from 0.62930 to 0.64530, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 70s 225ms/step - loss: 1.1880 - accuracy: 0.5774 - val_loss: 1.0032 - val_accuracy: 0.6453\n",
      "Epoch 14/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1630 - accuracy: 0.5871\n",
      "Epoch 14: val_accuracy did not improve from 0.64530\n",
      "312/312 [==============================] - 70s 225ms/step - loss: 1.1630 - accuracy: 0.5871 - val_loss: 1.1209 - val_accuracy: 0.6072\n",
      "Epoch 15/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1493 - accuracy: 0.5909\n",
      "Epoch 15: val_accuracy did not improve from 0.64530\n",
      "312/312 [==============================] - 67s 213ms/step - loss: 1.1493 - accuracy: 0.5909 - val_loss: 1.0080 - val_accuracy: 0.6395\n",
      "Epoch 16/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1268 - accuracy: 0.6008\n",
      "Epoch 16: val_accuracy improved from 0.64530 to 0.64540, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 65s 207ms/step - loss: 1.1268 - accuracy: 0.6008 - val_loss: 1.0041 - val_accuracy: 0.6454\n",
      "Epoch 17/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1035 - accuracy: 0.6091\n",
      "Epoch 17: val_accuracy improved from 0.64540 to 0.65370, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 65s 208ms/step - loss: 1.1035 - accuracy: 0.6091 - val_loss: 0.9827 - val_accuracy: 0.6537\n",
      "Epoch 18/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0883 - accuracy: 0.6173\n",
      "Epoch 18: val_accuracy did not improve from 0.65370\n",
      "312/312 [==============================] - 65s 208ms/step - loss: 1.0883 - accuracy: 0.6173 - val_loss: 1.1035 - val_accuracy: 0.6150\n",
      "Epoch 19/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0682 - accuracy: 0.6186\n",
      "Epoch 19: val_accuracy improved from 0.65370 to 0.65590, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 65s 207ms/step - loss: 1.0682 - accuracy: 0.6186 - val_loss: 0.9855 - val_accuracy: 0.6559\n",
      "Epoch 20/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0617 - accuracy: 0.6236\n",
      "Epoch 20: val_accuracy improved from 0.65590 to 0.67890, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 1.0617 - accuracy: 0.6236 - val_loss: 0.9060 - val_accuracy: 0.6789\n",
      "Epoch 21/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0445 - accuracy: 0.6296\n",
      "Epoch 21: val_accuracy did not improve from 0.67890\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 1.0445 - accuracy: 0.6296 - val_loss: 0.9890 - val_accuracy: 0.6515\n",
      "Epoch 22/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0268 - accuracy: 0.6373\n",
      "Epoch 22: val_accuracy did not improve from 0.67890\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 1.0268 - accuracy: 0.6373 - val_loss: 0.9139 - val_accuracy: 0.6789\n",
      "Epoch 23/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0158 - accuracy: 0.6407\n",
      "Epoch 23: val_accuracy improved from 0.67890 to 0.69250, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 1.0158 - accuracy: 0.6407 - val_loss: 0.8806 - val_accuracy: 0.6925\n",
      "Epoch 24/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9942 - accuracy: 0.6476\n",
      "Epoch 24: val_accuracy improved from 0.69250 to 0.69860, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 0.9942 - accuracy: 0.6476 - val_loss: 0.8598 - val_accuracy: 0.6986\n",
      "Epoch 25/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9839 - accuracy: 0.6534\n",
      "Epoch 25: val_accuracy improved from 0.69860 to 0.70540, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 0.9839 - accuracy: 0.6534 - val_loss: 0.8421 - val_accuracy: 0.7054\n",
      "Epoch 26/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9695 - accuracy: 0.6572\n",
      "Epoch 26: val_accuracy did not improve from 0.70540\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 0.9695 - accuracy: 0.6572 - val_loss: 0.8491 - val_accuracy: 0.7011\n",
      "Epoch 27/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9570 - accuracy: 0.6655\n",
      "Epoch 27: val_accuracy did not improve from 0.70540\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.9570 - accuracy: 0.6655 - val_loss: 0.8869 - val_accuracy: 0.6902\n",
      "Epoch 28/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9499 - accuracy: 0.6632\n",
      "Epoch 28: val_accuracy improved from 0.70540 to 0.71040, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.9499 - accuracy: 0.6632 - val_loss: 0.8210 - val_accuracy: 0.7104\n",
      "Epoch 29/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9331 - accuracy: 0.6714\n",
      "Epoch 29: val_accuracy did not improve from 0.71040\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 0.9331 - accuracy: 0.6714 - val_loss: 0.9009 - val_accuracy: 0.6901\n",
      "Epoch 30/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9259 - accuracy: 0.6729\n",
      "Epoch 30: val_accuracy improved from 0.71040 to 0.71430, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 0.9259 - accuracy: 0.6729 - val_loss: 0.8156 - val_accuracy: 0.7143\n",
      "Epoch 31/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9087 - accuracy: 0.6799\n",
      "Epoch 31: val_accuracy improved from 0.71430 to 0.72470, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.9087 - accuracy: 0.6799 - val_loss: 0.7798 - val_accuracy: 0.7247\n",
      "Epoch 32/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8979 - accuracy: 0.6845\n",
      "Epoch 32: val_accuracy did not improve from 0.72470\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 0.8979 - accuracy: 0.6845 - val_loss: 0.8207 - val_accuracy: 0.7113\n",
      "Epoch 33/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8940 - accuracy: 0.6861\n",
      "Epoch 33: val_accuracy improved from 0.72470 to 0.73530, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 0.8940 - accuracy: 0.6861 - val_loss: 0.7507 - val_accuracy: 0.7353\n",
      "Epoch 34/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8750 - accuracy: 0.6899\n",
      "Epoch 34: val_accuracy did not improve from 0.73530\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 0.8750 - accuracy: 0.6899 - val_loss: 0.7821 - val_accuracy: 0.7298\n",
      "Epoch 35/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8634 - accuracy: 0.6958\n",
      "Epoch 35: val_accuracy did not improve from 0.73530\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 0.8634 - accuracy: 0.6958 - val_loss: 0.7887 - val_accuracy: 0.7248\n",
      "Epoch 36/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8569 - accuracy: 0.6971\n",
      "Epoch 36: val_accuracy did not improve from 0.73530\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.8569 - accuracy: 0.6971 - val_loss: 0.8315 - val_accuracy: 0.7113\n",
      "Epoch 37/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8460 - accuracy: 0.7027\n",
      "Epoch 37: val_accuracy improved from 0.73530 to 0.74680, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.8460 - accuracy: 0.7027 - val_loss: 0.7338 - val_accuracy: 0.7468\n",
      "Epoch 38/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8408 - accuracy: 0.7063\n",
      "Epoch 38: val_accuracy did not improve from 0.74680\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.8408 - accuracy: 0.7063 - val_loss: 0.7586 - val_accuracy: 0.7322\n",
      "Epoch 39/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8275 - accuracy: 0.7109\n",
      "Epoch 39: val_accuracy did not improve from 0.74680\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.8275 - accuracy: 0.7109 - val_loss: 0.7749 - val_accuracy: 0.7326\n",
      "Epoch 40/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8218 - accuracy: 0.7111\n",
      "Epoch 40: val_accuracy improved from 0.74680 to 0.75550, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.8218 - accuracy: 0.7111 - val_loss: 0.7190 - val_accuracy: 0.7555\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.7190 - accuracy: 0.7555\n",
      "COMBINATION BEST ACCURACY:  0.7555000185966492\n",
      "\n",
      "COMBINATION: filter_size=5, dropout_rate=0.35, learning_rate=0.01\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 3.5165 - accuracy: 0.0978\n",
      "Epoch 1: val_accuracy improved from -inf to 0.09330, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 202ms/step - loss: 3.5165 - accuracy: 0.0978 - val_loss: 2.3040 - val_accuracy: 0.0933\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3034 - accuracy: 0.0990\n",
      "Epoch 2: val_accuracy did not improve from 0.09330\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 2.3034 - accuracy: 0.0990 - val_loss: 2.3033 - val_accuracy: 0.0933\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3032 - accuracy: 0.1005\n",
      "Epoch 3: val_accuracy improved from 0.09330 to 0.10170, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 2.3032 - accuracy: 0.1005 - val_loss: 2.3026 - val_accuracy: 0.1017\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.1009\n",
      "Epoch 4: val_accuracy did not improve from 0.10170\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 2.3033 - accuracy: 0.1009 - val_loss: 2.3036 - val_accuracy: 0.0994\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3032 - accuracy: 0.1003\n",
      "Epoch 5: val_accuracy did not improve from 0.10170\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 2.3032 - accuracy: 0.1003 - val_loss: 2.3036 - val_accuracy: 0.0994\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3034 - accuracy: 0.0984\n",
      "Epoch 6: val_accuracy did not improve from 0.10170\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 2.3034 - accuracy: 0.0984 - val_loss: 2.3037 - val_accuracy: 0.0973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3035 - accuracy: 0.0978\n",
      "Epoch 7: val_accuracy did not improve from 0.10170\n",
      "312/312 [==============================] - 62s 198ms/step - loss: 2.3035 - accuracy: 0.0978 - val_loss: 2.3031 - val_accuracy: 0.0994\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.1013\n",
      "Epoch 8: val_accuracy did not improve from 0.10170\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "312/312 [==============================] - 62s 198ms/step - loss: 2.3033 - accuracy: 0.1013 - val_loss: 2.3030 - val_accuracy: 0.0996\n",
      "Epoch 8: early stopping\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 2.3026 - accuracy: 0.1017\n",
      "COMBINATION BEST ACCURACY:  0.10170000046491623\n",
      "\n",
      "COMBINATION: filter_size=5, dropout_rate=0.35, learning_rate=0.001\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.8567 - accuracy: 0.3076\n",
      "Epoch 1: val_accuracy improved from -inf to 0.45620, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 203ms/step - loss: 1.8567 - accuracy: 0.3076 - val_loss: 1.4995 - val_accuracy: 0.4562\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5530 - accuracy: 0.4296\n",
      "Epoch 2: val_accuracy improved from 0.45620 to 0.51340, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.5530 - accuracy: 0.4296 - val_loss: 1.3294 - val_accuracy: 0.5134\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4235 - accuracy: 0.4847\n",
      "Epoch 3: val_accuracy improved from 0.51340 to 0.55180, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.4235 - accuracy: 0.4847 - val_loss: 1.2222 - val_accuracy: 0.5518\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3156 - accuracy: 0.5286\n",
      "Epoch 4: val_accuracy improved from 0.55180 to 0.58850, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 1.3156 - accuracy: 0.5286 - val_loss: 1.1649 - val_accuracy: 0.5885\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2324 - accuracy: 0.5580\n",
      "Epoch 5: val_accuracy improved from 0.58850 to 0.62690, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.2324 - accuracy: 0.5580 - val_loss: 1.0373 - val_accuracy: 0.6269\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1771 - accuracy: 0.5800\n",
      "Epoch 6: val_accuracy did not improve from 0.62690\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 1.1771 - accuracy: 0.5800 - val_loss: 1.0685 - val_accuracy: 0.6235\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1266 - accuracy: 0.5992\n",
      "Epoch 7: val_accuracy improved from 0.62690 to 0.66250, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 1.1266 - accuracy: 0.5992 - val_loss: 0.9698 - val_accuracy: 0.6625\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0867 - accuracy: 0.6124\n",
      "Epoch 8: val_accuracy improved from 0.66250 to 0.68280, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 1.0867 - accuracy: 0.6124 - val_loss: 0.8931 - val_accuracy: 0.6828\n",
      "Epoch 9/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0459 - accuracy: 0.6328\n",
      "Epoch 9: val_accuracy improved from 0.68280 to 0.70150, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 1.0459 - accuracy: 0.6328 - val_loss: 0.8487 - val_accuracy: 0.7015\n",
      "Epoch 10/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0060 - accuracy: 0.6458\n",
      "Epoch 10: val_accuracy did not improve from 0.70150\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 1.0060 - accuracy: 0.6458 - val_loss: 0.8759 - val_accuracy: 0.6924\n",
      "Epoch 11/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9876 - accuracy: 0.6513\n",
      "Epoch 11: val_accuracy improved from 0.70150 to 0.71410, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 65s 207ms/step - loss: 0.9876 - accuracy: 0.6513 - val_loss: 0.8283 - val_accuracy: 0.7141\n",
      "Epoch 12/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9717 - accuracy: 0.6592\n",
      "Epoch 12: val_accuracy did not improve from 0.71410\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 0.9717 - accuracy: 0.6592 - val_loss: 0.8530 - val_accuracy: 0.7015\n",
      "Epoch 13/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9507 - accuracy: 0.6672\n",
      "Epoch 13: val_accuracy did not improve from 0.71410\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 0.9507 - accuracy: 0.6672 - val_loss: 0.8245 - val_accuracy: 0.7087\n",
      "Epoch 14/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9291 - accuracy: 0.6738\n",
      "Epoch 14: val_accuracy did not improve from 0.71410\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 0.9291 - accuracy: 0.6738 - val_loss: 0.8323 - val_accuracy: 0.7141\n",
      "Epoch 15/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9188 - accuracy: 0.6778\n",
      "Epoch 15: val_accuracy improved from 0.71410 to 0.71890, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 0.9188 - accuracy: 0.6778 - val_loss: 0.7934 - val_accuracy: 0.7189\n",
      "Epoch 16/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9005 - accuracy: 0.6843\n",
      "Epoch 16: val_accuracy did not improve from 0.71890\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 0.9005 - accuracy: 0.6843 - val_loss: 0.8210 - val_accuracy: 0.7169\n",
      "Epoch 17/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8913 - accuracy: 0.6892\n",
      "Epoch 17: val_accuracy improved from 0.71890 to 0.72210, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 0.8913 - accuracy: 0.6892 - val_loss: 0.8285 - val_accuracy: 0.7221\n",
      "Epoch 18/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8866 - accuracy: 0.6897\n",
      "Epoch 18: val_accuracy did not improve from 0.72210\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 0.8866 - accuracy: 0.6897 - val_loss: 0.8363 - val_accuracy: 0.7059\n",
      "Epoch 19/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8781 - accuracy: 0.6946\n",
      "Epoch 19: val_accuracy improved from 0.72210 to 0.75000, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.8781 - accuracy: 0.6946 - val_loss: 0.7067 - val_accuracy: 0.7500\n",
      "Epoch 20/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8537 - accuracy: 0.7004\n",
      "Epoch 20: val_accuracy did not improve from 0.75000\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.8537 - accuracy: 0.7004 - val_loss: 0.8160 - val_accuracy: 0.7204\n",
      "Epoch 21/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8449 - accuracy: 0.7071\n",
      "Epoch 21: val_accuracy did not improve from 0.75000\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.8449 - accuracy: 0.7071 - val_loss: 0.7356 - val_accuracy: 0.7398\n",
      "Epoch 22/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8380 - accuracy: 0.7086\n",
      "Epoch 22: val_accuracy did not improve from 0.75000\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.8380 - accuracy: 0.7086 - val_loss: 0.7433 - val_accuracy: 0.7429\n",
      "Epoch 23/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8321 - accuracy: 0.7101\n",
      "Epoch 23: val_accuracy improved from 0.75000 to 0.75610, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.8321 - accuracy: 0.7101 - val_loss: 0.7076 - val_accuracy: 0.7561\n",
      "Epoch 24/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8283 - accuracy: 0.7128\n",
      "Epoch 24: val_accuracy did not improve from 0.75610\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 0.8283 - accuracy: 0.7128 - val_loss: 0.7296 - val_accuracy: 0.7454\n",
      "Epoch 25/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8246 - accuracy: 0.7108\n",
      "Epoch 25: val_accuracy did not improve from 0.75610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 64s 206ms/step - loss: 0.8246 - accuracy: 0.7108 - val_loss: 0.7408 - val_accuracy: 0.7468\n",
      "Epoch 26/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8171 - accuracy: 0.7154\n",
      "Epoch 26: val_accuracy improved from 0.75610 to 0.76870, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 0.8171 - accuracy: 0.7154 - val_loss: 0.6752 - val_accuracy: 0.7687\n",
      "Epoch 27/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8105 - accuracy: 0.7179\n",
      "Epoch 27: val_accuracy did not improve from 0.76870\n",
      "312/312 [==============================] - 64s 206ms/step - loss: 0.8105 - accuracy: 0.7179 - val_loss: 0.6725 - val_accuracy: 0.7657\n",
      "Epoch 28/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8053 - accuracy: 0.7210\n",
      "Epoch 28: val_accuracy did not improve from 0.76870\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 0.8053 - accuracy: 0.7210 - val_loss: 0.7200 - val_accuracy: 0.7527\n",
      "Epoch 29/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8019 - accuracy: 0.7227\n",
      "Epoch 29: val_accuracy did not improve from 0.76870\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 0.8019 - accuracy: 0.7227 - val_loss: 0.7388 - val_accuracy: 0.7431\n",
      "Epoch 30/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7863 - accuracy: 0.7280\n",
      "Epoch 30: val_accuracy did not improve from 0.76870\n",
      "312/312 [==============================] - 62s 200ms/step - loss: 0.7863 - accuracy: 0.7280 - val_loss: 0.7742 - val_accuracy: 0.7410\n",
      "Epoch 31/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7859 - accuracy: 0.7278\n",
      "Epoch 31: val_accuracy did not improve from 0.76870\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 0.7859 - accuracy: 0.7278 - val_loss: 0.7402 - val_accuracy: 0.7451\n",
      "Epoch 31: early stopping\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.6752 - accuracy: 0.7687\n",
      "COMBINATION BEST ACCURACY:  0.7687000036239624\n",
      "\n",
      "COMBINATION: filter_size=5, dropout_rate=0.35, learning_rate=0.0001\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.9489 - accuracy: 0.2763\n",
      "Epoch 1: val_accuracy improved from -inf to 0.39160, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 203ms/step - loss: 1.9489 - accuracy: 0.2763 - val_loss: 1.6569 - val_accuracy: 0.3916\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.7090 - accuracy: 0.3712\n",
      "Epoch 2: val_accuracy improved from 0.39160 to 0.43950, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 1.7090 - accuracy: 0.3712 - val_loss: 1.5575 - val_accuracy: 0.4395\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.6248 - accuracy: 0.4075\n",
      "Epoch 3: val_accuracy improved from 0.43950 to 0.44310, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.6248 - accuracy: 0.4075 - val_loss: 1.5292 - val_accuracy: 0.4431\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5685 - accuracy: 0.4272\n",
      "Epoch 4: val_accuracy improved from 0.44310 to 0.48870, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 203ms/step - loss: 1.5685 - accuracy: 0.4272 - val_loss: 1.4131 - val_accuracy: 0.4887\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5105 - accuracy: 0.4534\n",
      "Epoch 5: val_accuracy improved from 0.48870 to 0.49520, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 1.5105 - accuracy: 0.4534 - val_loss: 1.4043 - val_accuracy: 0.4952\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4583 - accuracy: 0.4742\n",
      "Epoch 6: val_accuracy did not improve from 0.49520\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.4583 - accuracy: 0.4742 - val_loss: 1.4445 - val_accuracy: 0.4846\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4191 - accuracy: 0.4868\n",
      "Epoch 7: val_accuracy improved from 0.49520 to 0.51630, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.4191 - accuracy: 0.4868 - val_loss: 1.3389 - val_accuracy: 0.5163\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3760 - accuracy: 0.5064\n",
      "Epoch 8: val_accuracy improved from 0.51630 to 0.52270, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 1.3760 - accuracy: 0.5064 - val_loss: 1.3206 - val_accuracy: 0.5227\n",
      "Epoch 9/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3454 - accuracy: 0.5159\n",
      "Epoch 9: val_accuracy improved from 0.52270 to 0.54520, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 1.3454 - accuracy: 0.5159 - val_loss: 1.2720 - val_accuracy: 0.5452\n",
      "Epoch 10/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3083 - accuracy: 0.5330\n",
      "Epoch 10: val_accuracy improved from 0.54520 to 0.57410, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 1.3083 - accuracy: 0.5330 - val_loss: 1.1932 - val_accuracy: 0.5741\n",
      "Epoch 11/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2799 - accuracy: 0.5381\n",
      "Epoch 11: val_accuracy did not improve from 0.57410\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 1.2799 - accuracy: 0.5381 - val_loss: 1.1912 - val_accuracy: 0.5692\n",
      "Epoch 12/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2608 - accuracy: 0.5467\n",
      "Epoch 12: val_accuracy improved from 0.57410 to 0.59080, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 1.2608 - accuracy: 0.5467 - val_loss: 1.1368 - val_accuracy: 0.5908\n",
      "Epoch 13/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2359 - accuracy: 0.5583\n",
      "Epoch 13: val_accuracy improved from 0.59080 to 0.59880, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 203ms/step - loss: 1.2359 - accuracy: 0.5583 - val_loss: 1.1340 - val_accuracy: 0.5988\n",
      "Epoch 14/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2071 - accuracy: 0.5688\n",
      "Epoch 14: val_accuracy did not improve from 0.59880\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 1.2071 - accuracy: 0.5688 - val_loss: 1.2480 - val_accuracy: 0.5683\n",
      "Epoch 15/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1925 - accuracy: 0.5725\n",
      "Epoch 15: val_accuracy improved from 0.59880 to 0.63190, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 206ms/step - loss: 1.1925 - accuracy: 0.5725 - val_loss: 1.0307 - val_accuracy: 0.6319\n",
      "Epoch 16/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1718 - accuracy: 0.5815\n",
      "Epoch 16: val_accuracy did not improve from 0.63190\n",
      "312/312 [==============================] - 64s 206ms/step - loss: 1.1718 - accuracy: 0.5815 - val_loss: 1.0516 - val_accuracy: 0.6281\n",
      "Epoch 17/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1497 - accuracy: 0.5913\n",
      "Epoch 17: val_accuracy did not improve from 0.63190\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 1.1497 - accuracy: 0.5913 - val_loss: 1.0342 - val_accuracy: 0.6274\n",
      "Epoch 18/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1322 - accuracy: 0.5978\n",
      "Epoch 18: val_accuracy improved from 0.63190 to 0.64530, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 1.1322 - accuracy: 0.5978 - val_loss: 0.9903 - val_accuracy: 0.6453\n",
      "Epoch 19/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1166 - accuracy: 0.6038\n",
      "Epoch 19: val_accuracy improved from 0.64530 to 0.64850, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 65s 207ms/step - loss: 1.1166 - accuracy: 0.6038 - val_loss: 0.9675 - val_accuracy: 0.6485\n",
      "Epoch 20/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0966 - accuracy: 0.6077\n",
      "Epoch 20: val_accuracy did not improve from 0.64850\n",
      "312/312 [==============================] - 64s 206ms/step - loss: 1.0966 - accuracy: 0.6077 - val_loss: 1.0334 - val_accuracy: 0.6359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0868 - accuracy: 0.6166\n",
      "Epoch 21: val_accuracy improved from 0.64850 to 0.65060, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 1.0868 - accuracy: 0.6166 - val_loss: 1.0010 - val_accuracy: 0.6506\n",
      "Epoch 22/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0731 - accuracy: 0.6193\n",
      "Epoch 22: val_accuracy improved from 0.65060 to 0.65660, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.0731 - accuracy: 0.6193 - val_loss: 0.9669 - val_accuracy: 0.6566\n",
      "Epoch 23/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0655 - accuracy: 0.6198\n",
      "Epoch 23: val_accuracy improved from 0.65660 to 0.67190, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 1.0655 - accuracy: 0.6198 - val_loss: 0.9202 - val_accuracy: 0.6719\n",
      "Epoch 24/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0451 - accuracy: 0.6291\n",
      "Epoch 24: val_accuracy did not improve from 0.67190\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.0451 - accuracy: 0.6291 - val_loss: 0.9775 - val_accuracy: 0.6541\n",
      "Epoch 25/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0270 - accuracy: 0.6370\n",
      "Epoch 25: val_accuracy improved from 0.67190 to 0.68490, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.0270 - accuracy: 0.6370 - val_loss: 0.8909 - val_accuracy: 0.6849\n",
      "Epoch 26/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0241 - accuracy: 0.6372\n",
      "Epoch 26: val_accuracy did not improve from 0.68490\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 1.0241 - accuracy: 0.6372 - val_loss: 0.9439 - val_accuracy: 0.6707\n",
      "Epoch 27/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0021 - accuracy: 0.6461\n",
      "Epoch 27: val_accuracy did not improve from 0.68490\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.0021 - accuracy: 0.6461 - val_loss: 0.9618 - val_accuracy: 0.6607\n",
      "Epoch 28/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9922 - accuracy: 0.6459\n",
      "Epoch 28: val_accuracy did not improve from 0.68490\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 0.9922 - accuracy: 0.6459 - val_loss: 0.9501 - val_accuracy: 0.6694\n",
      "Epoch 29/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9816 - accuracy: 0.6523\n",
      "Epoch 29: val_accuracy improved from 0.68490 to 0.69630, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 0.9816 - accuracy: 0.6523 - val_loss: 0.8815 - val_accuracy: 0.6963\n",
      "Epoch 30/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9796 - accuracy: 0.6530\n",
      "Epoch 30: val_accuracy did not improve from 0.69630\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 0.9796 - accuracy: 0.6530 - val_loss: 0.8988 - val_accuracy: 0.6849\n",
      "Epoch 31/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9707 - accuracy: 0.6546\n",
      "Epoch 31: val_accuracy improved from 0.69630 to 0.70580, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 0.9707 - accuracy: 0.6546 - val_loss: 0.8471 - val_accuracy: 0.7058\n",
      "Epoch 32/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9607 - accuracy: 0.6616\n",
      "Epoch 32: val_accuracy did not improve from 0.70580\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 0.9607 - accuracy: 0.6616 - val_loss: 0.9256 - val_accuracy: 0.6775\n",
      "Epoch 33/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9438 - accuracy: 0.6669\n",
      "Epoch 33: val_accuracy improved from 0.70580 to 0.71660, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 0.9438 - accuracy: 0.6669 - val_loss: 0.8143 - val_accuracy: 0.7166\n",
      "Epoch 34/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9399 - accuracy: 0.6692\n",
      "Epoch 34: val_accuracy did not improve from 0.71660\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 0.9399 - accuracy: 0.6692 - val_loss: 0.8167 - val_accuracy: 0.7128\n",
      "Epoch 35/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9297 - accuracy: 0.6714\n",
      "Epoch 35: val_accuracy did not improve from 0.71660\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 0.9297 - accuracy: 0.6714 - val_loss: 0.8559 - val_accuracy: 0.7056\n",
      "Epoch 36/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9177 - accuracy: 0.6748\n",
      "Epoch 36: val_accuracy did not improve from 0.71660\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 0.9177 - accuracy: 0.6748 - val_loss: 0.9219 - val_accuracy: 0.6820\n",
      "Epoch 37/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9087 - accuracy: 0.6798\n",
      "Epoch 37: val_accuracy did not improve from 0.71660\n",
      "312/312 [==============================] - 64s 206ms/step - loss: 0.9087 - accuracy: 0.6798 - val_loss: 0.8544 - val_accuracy: 0.7058\n",
      "Epoch 38/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9017 - accuracy: 0.6821\n",
      "Epoch 38: val_accuracy improved from 0.71660 to 0.72510, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.9017 - accuracy: 0.6821 - val_loss: 0.7956 - val_accuracy: 0.7251\n",
      "Epoch 39/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8894 - accuracy: 0.6842\n",
      "Epoch 39: val_accuracy did not improve from 0.72510\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 0.8894 - accuracy: 0.6842 - val_loss: 0.8068 - val_accuracy: 0.7203\n",
      "Epoch 40/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8854 - accuracy: 0.6876\n",
      "Epoch 40: val_accuracy improved from 0.72510 to 0.72670, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 0.8854 - accuracy: 0.6876 - val_loss: 0.7899 - val_accuracy: 0.7267\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.7899 - accuracy: 0.7267\n",
      "COMBINATION BEST ACCURACY:  0.7267000079154968\n",
      "\n",
      "COMBINATION: filter_size=5, dropout_rate=0.5, learning_rate=0.01\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.6434 - accuracy: 0.1034\n",
      "Epoch 1: val_accuracy improved from -inf to 0.09790, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 202ms/step - loss: 2.6434 - accuracy: 0.1034 - val_loss: 2.3038 - val_accuracy: 0.0979\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3034 - accuracy: 0.0957\n",
      "Epoch 2: val_accuracy improved from 0.09790 to 0.10150, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 2.3034 - accuracy: 0.0957 - val_loss: 2.3036 - val_accuracy: 0.1015\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.0982\n",
      "Epoch 3: val_accuracy improved from 0.10150 to 0.10300, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 2.3033 - accuracy: 0.0982 - val_loss: 2.3032 - val_accuracy: 0.1030\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3032 - accuracy: 0.0993\n",
      "Epoch 4: val_accuracy did not improve from 0.10300\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 2.3032 - accuracy: 0.0993 - val_loss: 2.3028 - val_accuracy: 0.0979\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3033 - accuracy: 0.0984\n",
      "Epoch 5: val_accuracy did not improve from 0.10300\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 2.3033 - accuracy: 0.0984 - val_loss: 2.3038 - val_accuracy: 0.0979\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3034 - accuracy: 0.1009\n",
      "Epoch 6: val_accuracy did not improve from 0.10300\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 2.3034 - accuracy: 0.1009 - val_loss: 2.3029 - val_accuracy: 0.0996\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3034 - accuracy: 0.0969\n",
      "Epoch 7: val_accuracy did not improve from 0.10300\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 2.3034 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.3034 - accuracy: 0.1009\n",
      "Epoch 8: val_accuracy did not improve from 0.10300\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "312/312 [==============================] - 62s 198ms/step - loss: 2.3034 - accuracy: 0.1009 - val_loss: 2.3040 - val_accuracy: 0.0973\n",
      "Epoch 8: early stopping\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 2.3032 - accuracy: 0.1030\n",
      "COMBINATION BEST ACCURACY:  0.10300000011920929\n",
      "\n",
      "COMBINATION: filter_size=5, dropout_rate=0.5, learning_rate=0.001\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.9312 - accuracy: 0.2801\n",
      "Epoch 1: val_accuracy improved from -inf to 0.39610, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 200ms/step - loss: 1.9312 - accuracy: 0.2801 - val_loss: 1.6371 - val_accuracy: 0.3961\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.6540 - accuracy: 0.3909\n",
      "Epoch 2: val_accuracy improved from 0.39610 to 0.46980, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 62s 199ms/step - loss: 1.6540 - accuracy: 0.3909 - val_loss: 1.4447 - val_accuracy: 0.4698\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5490 - accuracy: 0.4318\n",
      "Epoch 3: val_accuracy improved from 0.46980 to 0.48320, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 62s 200ms/step - loss: 1.5490 - accuracy: 0.4318 - val_loss: 1.4348 - val_accuracy: 0.4832\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4623 - accuracy: 0.4690\n",
      "Epoch 4: val_accuracy improved from 0.48320 to 0.53410, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 62s 199ms/step - loss: 1.4623 - accuracy: 0.4690 - val_loss: 1.2855 - val_accuracy: 0.5341\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4013 - accuracy: 0.4944\n",
      "Epoch 5: val_accuracy did not improve from 0.53410\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.4013 - accuracy: 0.4944 - val_loss: 1.4034 - val_accuracy: 0.5046\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3521 - accuracy: 0.5136\n",
      "Epoch 6: val_accuracy improved from 0.53410 to 0.56400, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 62s 200ms/step - loss: 1.3521 - accuracy: 0.5136 - val_loss: 1.2315 - val_accuracy: 0.5640\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3161 - accuracy: 0.5301\n",
      "Epoch 7: val_accuracy improved from 0.56400 to 0.56580, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 62s 200ms/step - loss: 1.3161 - accuracy: 0.5301 - val_loss: 1.1905 - val_accuracy: 0.5658\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2717 - accuracy: 0.5473\n",
      "Epoch 8: val_accuracy improved from 0.56580 to 0.59180, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 62s 199ms/step - loss: 1.2717 - accuracy: 0.5473 - val_loss: 1.1337 - val_accuracy: 0.5918\n",
      "Epoch 9/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2332 - accuracy: 0.5575\n",
      "Epoch 9: val_accuracy improved from 0.59180 to 0.61160, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 62s 200ms/step - loss: 1.2332 - accuracy: 0.5575 - val_loss: 1.0997 - val_accuracy: 0.6116\n",
      "Epoch 10/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2091 - accuracy: 0.5684\n",
      "Epoch 10: val_accuracy did not improve from 0.61160\n",
      "312/312 [==============================] - 62s 198ms/step - loss: 1.2091 - accuracy: 0.5684 - val_loss: 1.1591 - val_accuracy: 0.5881\n",
      "Epoch 11/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1795 - accuracy: 0.5804\n",
      "Epoch 11: val_accuracy did not improve from 0.61160\n",
      "312/312 [==============================] - 62s 200ms/step - loss: 1.1795 - accuracy: 0.5804 - val_loss: 1.1351 - val_accuracy: 0.6007\n",
      "Epoch 12/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1519 - accuracy: 0.5898\n",
      "Epoch 12: val_accuracy did not improve from 0.61160\n",
      "312/312 [==============================] - 68s 217ms/step - loss: 1.1519 - accuracy: 0.5898 - val_loss: 1.0730 - val_accuracy: 0.6116\n",
      "Epoch 13/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1323 - accuracy: 0.5970\n",
      "Epoch 13: val_accuracy improved from 0.61160 to 0.62130, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 65s 209ms/step - loss: 1.1323 - accuracy: 0.5970 - val_loss: 1.0933 - val_accuracy: 0.6213\n",
      "Epoch 14/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1247 - accuracy: 0.6019\n",
      "Epoch 14: val_accuracy improved from 0.62130 to 0.62310, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 1.1247 - accuracy: 0.6019 - val_loss: 1.0558 - val_accuracy: 0.6231\n",
      "Epoch 15/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1026 - accuracy: 0.6117\n",
      "Epoch 15: val_accuracy improved from 0.62310 to 0.63630, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 1.1026 - accuracy: 0.6117 - val_loss: 1.0378 - val_accuracy: 0.6363\n",
      "Epoch 16/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0945 - accuracy: 0.6127\n",
      "Epoch 16: val_accuracy improved from 0.63630 to 0.65360, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 62s 200ms/step - loss: 1.0945 - accuracy: 0.6127 - val_loss: 0.9689 - val_accuracy: 0.6536\n",
      "Epoch 17/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0833 - accuracy: 0.6155\n",
      "Epoch 17: val_accuracy improved from 0.65360 to 0.66020, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 62s 200ms/step - loss: 1.0833 - accuracy: 0.6155 - val_loss: 0.9623 - val_accuracy: 0.6602\n",
      "Epoch 18/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0658 - accuracy: 0.6245\n",
      "Epoch 18: val_accuracy did not improve from 0.66020\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.0658 - accuracy: 0.6245 - val_loss: 0.9828 - val_accuracy: 0.6405\n",
      "Epoch 19/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0552 - accuracy: 0.6271\n",
      "Epoch 19: val_accuracy did not improve from 0.66020\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.0552 - accuracy: 0.6271 - val_loss: 0.9681 - val_accuracy: 0.6475\n",
      "Epoch 20/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0449 - accuracy: 0.6350\n",
      "Epoch 20: val_accuracy improved from 0.66020 to 0.67980, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 1.0449 - accuracy: 0.6350 - val_loss: 0.9073 - val_accuracy: 0.6798\n",
      "Epoch 21/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0377 - accuracy: 0.6348\n",
      "Epoch 21: val_accuracy improved from 0.67980 to 0.68860, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 1.0377 - accuracy: 0.6348 - val_loss: 0.8816 - val_accuracy: 0.6886\n",
      "Epoch 22/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0339 - accuracy: 0.6346\n",
      "Epoch 22: val_accuracy did not improve from 0.68860\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 1.0339 - accuracy: 0.6346 - val_loss: 0.9162 - val_accuracy: 0.6697\n",
      "Epoch 23/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0175 - accuracy: 0.6450\n",
      "Epoch 23: val_accuracy did not improve from 0.68860\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 1.0175 - accuracy: 0.6450 - val_loss: 0.9851 - val_accuracy: 0.6473\n",
      "Epoch 24/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0253 - accuracy: 0.6378\n",
      "Epoch 24: val_accuracy did not improve from 0.68860\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 1.0253 - accuracy: 0.6378 - val_loss: 1.1216 - val_accuracy: 0.6152\n",
      "Epoch 25/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0081 - accuracy: 0.6472\n",
      "Epoch 25: val_accuracy did not improve from 0.68860\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 1.0081 - accuracy: 0.6472 - val_loss: 0.9889 - val_accuracy: 0.6556\n",
      "Epoch 26/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9929 - accuracy: 0.6523\n",
      "Epoch 26: val_accuracy did not improve from 0.68860\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "312/312 [==============================] - 62s 199ms/step - loss: 0.9929 - accuracy: 0.6523 - val_loss: 0.9258 - val_accuracy: 0.6668\n",
      "Epoch 26: early stopping\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.8816 - accuracy: 0.6886\n",
      "COMBINATION BEST ACCURACY:  0.6886000037193298\n",
      "\n",
      "COMBINATION: filter_size=5, dropout_rate=0.5, learning_rate=0.0001\n",
      "Epoch 1/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 2.0433 - accuracy: 0.2408\n",
      "Epoch 1: val_accuracy improved from -inf to 0.37150, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 202ms/step - loss: 2.0433 - accuracy: 0.2408 - val_loss: 1.7589 - val_accuracy: 0.3715\n",
      "Epoch 2/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.7841 - accuracy: 0.3410\n",
      "Epoch 2: val_accuracy improved from 0.37150 to 0.42380, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.7841 - accuracy: 0.3410 - val_loss: 1.5871 - val_accuracy: 0.4238\n",
      "Epoch 3/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.6816 - accuracy: 0.3812\n",
      "Epoch 3: val_accuracy improved from 0.42380 to 0.45100, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.6816 - accuracy: 0.3812 - val_loss: 1.4915 - val_accuracy: 0.4510\n",
      "Epoch 4/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.6258 - accuracy: 0.4022\n",
      "Epoch 4: val_accuracy improved from 0.45100 to 0.47040, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.6258 - accuracy: 0.4022 - val_loss: 1.4480 - val_accuracy: 0.4704\n",
      "Epoch 5/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5806 - accuracy: 0.4235\n",
      "Epoch 5: val_accuracy improved from 0.47040 to 0.48010, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.5806 - accuracy: 0.4235 - val_loss: 1.4179 - val_accuracy: 0.4801\n",
      "Epoch 6/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5385 - accuracy: 0.4375\n",
      "Epoch 6: val_accuracy improved from 0.48010 to 0.48840, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.5385 - accuracy: 0.4375 - val_loss: 1.4070 - val_accuracy: 0.4884\n",
      "Epoch 7/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5004 - accuracy: 0.4552\n",
      "Epoch 7: val_accuracy improved from 0.48840 to 0.50140, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 1.5004 - accuracy: 0.4552 - val_loss: 1.3650 - val_accuracy: 0.5014\n",
      "Epoch 8/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4694 - accuracy: 0.4663\n",
      "Epoch 8: val_accuracy improved from 0.50140 to 0.50540, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 202ms/step - loss: 1.4694 - accuracy: 0.4663 - val_loss: 1.3682 - val_accuracy: 0.5054\n",
      "Epoch 9/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4385 - accuracy: 0.4785\n",
      "Epoch 9: val_accuracy improved from 0.50540 to 0.52630, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 1.4385 - accuracy: 0.4785 - val_loss: 1.2974 - val_accuracy: 0.5263\n",
      "Epoch 10/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.4159 - accuracy: 0.4901\n",
      "Epoch 10: val_accuracy improved from 0.52630 to 0.55220, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 66s 211ms/step - loss: 1.4159 - accuracy: 0.4901 - val_loss: 1.2340 - val_accuracy: 0.5522\n",
      "Epoch 11/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3794 - accuracy: 0.5023\n",
      "Epoch 11: val_accuracy did not improve from 0.55220\n",
      "312/312 [==============================] - 65s 207ms/step - loss: 1.3794 - accuracy: 0.5023 - val_loss: 1.3116 - val_accuracy: 0.5285\n",
      "Epoch 12/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3511 - accuracy: 0.5115\n",
      "Epoch 12: val_accuracy improved from 0.55220 to 0.56280, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 1.3511 - accuracy: 0.5115 - val_loss: 1.2179 - val_accuracy: 0.5628\n",
      "Epoch 13/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3275 - accuracy: 0.5232\n",
      "Epoch 13: val_accuracy improved from 0.56280 to 0.57850, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 206ms/step - loss: 1.3275 - accuracy: 0.5232 - val_loss: 1.1732 - val_accuracy: 0.5785\n",
      "Epoch 14/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3062 - accuracy: 0.5281\n",
      "Epoch 14: val_accuracy did not improve from 0.57850\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 1.3062 - accuracy: 0.5281 - val_loss: 1.1836 - val_accuracy: 0.5750\n",
      "Epoch 15/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2819 - accuracy: 0.5371\n",
      "Epoch 15: val_accuracy improved from 0.57850 to 0.58650, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 1.2819 - accuracy: 0.5371 - val_loss: 1.1488 - val_accuracy: 0.5865\n",
      "Epoch 16/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2653 - accuracy: 0.5483\n",
      "Epoch 16: val_accuracy improved from 0.58650 to 0.59450, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 204ms/step - loss: 1.2653 - accuracy: 0.5483 - val_loss: 1.1171 - val_accuracy: 0.5945\n",
      "Epoch 17/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2436 - accuracy: 0.5550\n",
      "Epoch 17: val_accuracy improved from 0.59450 to 0.59670, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 203ms/step - loss: 1.2436 - accuracy: 0.5550 - val_loss: 1.1352 - val_accuracy: 0.5967\n",
      "Epoch 18/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2301 - accuracy: 0.5606\n",
      "Epoch 18: val_accuracy did not improve from 0.59670\n",
      "312/312 [==============================] - 63s 203ms/step - loss: 1.2301 - accuracy: 0.5606 - val_loss: 1.1960 - val_accuracy: 0.5879\n",
      "Epoch 19/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.2103 - accuracy: 0.5692\n",
      "Epoch 19: val_accuracy improved from 0.59670 to 0.60000, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 206ms/step - loss: 1.2103 - accuracy: 0.5692 - val_loss: 1.1412 - val_accuracy: 0.6000\n",
      "Epoch 20/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1906 - accuracy: 0.5735\n",
      "Epoch 20: val_accuracy improved from 0.60000 to 0.60080, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 1.1906 - accuracy: 0.5735 - val_loss: 1.1311 - val_accuracy: 0.6008\n",
      "Epoch 21/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1743 - accuracy: 0.5787\n",
      "Epoch 21: val_accuracy improved from 0.60080 to 0.64590, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 65s 209ms/step - loss: 1.1743 - accuracy: 0.5787 - val_loss: 0.9987 - val_accuracy: 0.6459\n",
      "Epoch 22/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1628 - accuracy: 0.5856\n",
      "Epoch 22: val_accuracy did not improve from 0.64590\n",
      "312/312 [==============================] - 65s 209ms/step - loss: 1.1628 - accuracy: 0.5856 - val_loss: 1.0449 - val_accuracy: 0.6309\n",
      "Epoch 23/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1442 - accuracy: 0.5917\n",
      "Epoch 23: val_accuracy did not improve from 0.64590\n",
      "312/312 [==============================] - 64s 206ms/step - loss: 1.1442 - accuracy: 0.5917 - val_loss: 1.0223 - val_accuracy: 0.6355\n",
      "Epoch 24/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1344 - accuracy: 0.5981\n",
      "Epoch 24: val_accuracy did not improve from 0.64590\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 1.1344 - accuracy: 0.5981 - val_loss: 1.0307 - val_accuracy: 0.6299\n",
      "Epoch 25/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1175 - accuracy: 0.6015\n",
      "Epoch 25: val_accuracy did not improve from 0.64590\n",
      "312/312 [==============================] - 64s 206ms/step - loss: 1.1175 - accuracy: 0.6015 - val_loss: 1.0351 - val_accuracy: 0.6314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1035 - accuracy: 0.6061\n",
      "Epoch 26: val_accuracy did not improve from 0.64590\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "312/312 [==============================] - 63s 201ms/step - loss: 1.1035 - accuracy: 0.6061 - val_loss: 0.9923 - val_accuracy: 0.6451\n",
      "Epoch 26: early stopping\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.9987 - accuracy: 0.6459\n",
      "COMBINATION BEST ACCURACY:  0.6459000110626221\n"
     ]
    }
   ],
   "source": [
    "for filter_size in filter_sizes:\n",
    "    \n",
    "    for dropout_rate in dropout_rates:\n",
    "        \n",
    "        for learning_rate in learning_rates:\n",
    "            \n",
    "            print(\"\\n\" + f\"COMBINATION: filter_size={filter_size}, dropout_rate={dropout_rate}, learning_rate={learning_rate}\")\n",
    "            \n",
    "            # Initialise batch size, steps per epoch, number of epochs\n",
    "            batch_size = 128\n",
    "            steps_per_epoch = X_train_set.shape[0] // batch_size\n",
    "            num_epochs = 40\n",
    "\n",
    "             # Define Callback\n",
    "            callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1,  restore_best_weights=True)\n",
    "\n",
    "            # Define the ModelCheckpoint callback\n",
    "            checkpoint_callback = ModelCheckpoint(\n",
    "                monitor='val_accuracy',\n",
    "                save_best_only=True,\n",
    "                mode='max',\n",
    "                verbose=1,\n",
    "                filepath='cnn_model.h5'\n",
    "            )\n",
    "                \n",
    "            # Build the model\n",
    "            model = create_Model1(filter_size, dropout_rate, learning_rate)\n",
    "            \n",
    "            # Train CNN on the training data\n",
    "            r = model.fit(train_generator, validation_data=(X_val, Y_val), steps_per_epoch=steps_per_epoch, epochs = num_epochs, batch_size=batch_size, callbacks=[checkpoint_callback, callback])\n",
    "\n",
    "            # Load the best model\n",
    "            best_model = load_model('cnn_model.h5')\n",
    "            \n",
    "            # Evaluate on the validation data\n",
    "            val_loss, val_accuracy = best_model.evaluate(X_val, Y_val)\n",
    "\n",
    "            results[filter_size, dropout_rate, learning_rate] = {'accuracy': val_accuracy,  'loss': val_loss, 'history': r}\n",
    "            \n",
    "            print(\"COMBINATION BEST ACCURACY: \", val_accuracy)\n",
    "            \n",
    "            if val_accuracy > best_combination[1][0]:\n",
    "                best_combination = [ [filter_size, dropout_rate, learning_rate], [val_accuracy, val_loss, r] ]\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(3, 0.2, 0.01): {'accuracy': 0.10400000214576721, 'loss': 2.3034026622772217, 'history': <keras.src.callbacks.History object at 0x000002341006B190>}, (3, 0.2, 0.001): {'accuracy': 0.784500002861023, 'loss': 0.6193900108337402, 'history': <keras.src.callbacks.History object at 0x000002341921DE40>}, (3, 0.2, 0.0001): {'accuracy': 0.722100019454956, 'loss': 0.8026576042175293, 'history': <keras.src.callbacks.History object at 0x000002341E9AF4C0>}, (3, 0.35, 0.01): {'accuracy': 0.1023000031709671, 'loss': 2.302743673324585, 'history': <keras.src.callbacks.History object at 0x0000023473FF7250>}, (3, 0.35, 0.001): {'accuracy': 0.7246000170707703, 'loss': 0.7910837531089783, 'history': <keras.src.callbacks.History object at 0x00000234AAC6A770>}, (3, 0.35, 0.0001): {'accuracy': 0.6759999990463257, 'loss': 0.9356396198272705, 'history': <keras.src.callbacks.History object at 0x00000234AE6FC820>}, (3, 0.5, 0.01): {'accuracy': 0.10400000214576721, 'loss': 2.3033082485198975, 'history': <keras.src.callbacks.History object at 0x00000234B0A261A0>}, (3, 0.5, 0.001): {'accuracy': 0.6797999739646912, 'loss': 0.9394949078559875, 'history': <keras.src.callbacks.History object at 0x00000234B0E5BAF0>}, (3, 0.5, 0.0001): {'accuracy': 0.6359999775886536, 'loss': 1.0352979898452759, 'history': <keras.src.callbacks.History object at 0x00000234191FFB80>}, (5, 0.2, 0.01): {'accuracy': 0.10300000011920929, 'loss': 2.302741289138794, 'history': <keras.src.callbacks.History object at 0x000002341912D630>}, (5, 0.2, 0.001): {'accuracy': 0.757099986076355, 'loss': 0.7047996520996094, 'history': <keras.src.callbacks.History object at 0x00000234A5EB96C0>}, (5, 0.2, 0.0001): {'accuracy': 0.7555000185966492, 'loss': 0.7190116047859192, 'history': <keras.src.callbacks.History object at 0x00000234A6131090>}, (5, 0.35, 0.01): {'accuracy': 0.10170000046491623, 'loss': 2.3025543689727783, 'history': <keras.src.callbacks.History object at 0x00000234A7651C90>}, (5, 0.35, 0.001): {'accuracy': 0.7687000036239624, 'loss': 0.6751807928085327, 'history': <keras.src.callbacks.History object at 0x00000234A7823D30>}, (5, 0.35, 0.0001): {'accuracy': 0.7267000079154968, 'loss': 0.7898671627044678, 'history': <keras.src.callbacks.History object at 0x00000234B10B7F40>}, (5, 0.5, 0.01): {'accuracy': 0.10300000011920929, 'loss': 2.3031716346740723, 'history': <keras.src.callbacks.History object at 0x00000234C38D4370>}, (5, 0.5, 0.001): {'accuracy': 0.6886000037193298, 'loss': 0.8815532326698303, 'history': <keras.src.callbacks.History object at 0x00000234A60F04F0>}, (5, 0.5, 0.0001): {'accuracy': 0.6459000110626221, 'loss': 0.9987438321113586, 'history': <keras.src.callbacks.History object at 0x00000234A75F9E40>}}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination with best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COMBINATION: filter_size=3, dropout_rate=0.2, learning_rate=0.001\n",
      "Accuracy:  0.784500002861023\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + f\"COMBINATION: filter_size={best_combination[0][0]}, dropout_rate={best_combination[0][1]}, learning_rate={best_combination[0][2]}\")\n",
    "print(\"Accuracy: \", best_combination[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Accuracy per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x234a2e40430>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(best_combination[1][2].history['accuracy'], label='accuracy')\n",
    "plt.plot(best_combination[1][2].history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x234a2ecb400>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(best_combination[1][2].history['loss'], label='loss')\n",
    "plt.plot(best_combination[1][2].history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the tuned model on entire train set and test using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 1.5194 - accuracy: 0.4477\n",
      "Epoch 1: accuracy improved from -inf to 0.44766, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 50s 124ms/step - loss: 1.5194 - accuracy: 0.4477\n",
      "Epoch 2/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 1.0536 - accuracy: 0.6253\n",
      "Epoch 2: accuracy improved from 0.44766 to 0.62526, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 49s 125ms/step - loss: 1.0536 - accuracy: 0.6253\n",
      "Epoch 3/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.8504 - accuracy: 0.7012\n",
      "Epoch 3: accuracy improved from 0.62526 to 0.70124, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 48s 122ms/step - loss: 0.8504 - accuracy: 0.7012\n",
      "Epoch 4/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.7212 - accuracy: 0.7474\n",
      "Epoch 4: accuracy improved from 0.70124 to 0.74737, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 48s 123ms/step - loss: 0.7212 - accuracy: 0.7474\n",
      "Epoch 5/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6014 - accuracy: 0.7886\n",
      "Epoch 5: accuracy improved from 0.74737 to 0.78860, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 48s 123ms/step - loss: 0.6014 - accuracy: 0.7886\n",
      "Epoch 6/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5024 - accuracy: 0.8240\n",
      "Epoch 6: accuracy improved from 0.78860 to 0.82397, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 48s 124ms/step - loss: 0.5024 - accuracy: 0.8240\n",
      "Epoch 7/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4194 - accuracy: 0.8511\n",
      "Epoch 7: accuracy improved from 0.82397 to 0.85112, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 49s 125ms/step - loss: 0.4194 - accuracy: 0.8511\n",
      "Epoch 8/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3332 - accuracy: 0.8825\n",
      "Epoch 8: accuracy improved from 0.85112 to 0.88248, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 49s 124ms/step - loss: 0.3332 - accuracy: 0.8825\n",
      "Epoch 9/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2826 - accuracy: 0.8997\n",
      "Epoch 9: accuracy improved from 0.88248 to 0.89974, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 49s 126ms/step - loss: 0.2826 - accuracy: 0.8997\n",
      "Epoch 10/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2301 - accuracy: 0.9189\n",
      "Epoch 10: accuracy improved from 0.89974 to 0.91893, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 48s 124ms/step - loss: 0.2301 - accuracy: 0.9189\n",
      "Epoch 11/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2011 - accuracy: 0.9278\n",
      "Epoch 11: accuracy improved from 0.91893 to 0.92784, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 50s 128ms/step - loss: 0.2011 - accuracy: 0.9278\n",
      "Epoch 12/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1708 - accuracy: 0.9402\n",
      "Epoch 12: accuracy improved from 0.92784 to 0.94017, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.1708 - accuracy: 0.9402\n",
      "Epoch 13/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.9461\n",
      "Epoch 13: accuracy improved from 0.94017 to 0.94610, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 50s 127ms/step - loss: 0.1539 - accuracy: 0.9461\n",
      "Epoch 14/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1412 - accuracy: 0.9508\n",
      "Epoch 14: accuracy improved from 0.94610 to 0.95079, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 52s 133ms/step - loss: 0.1412 - accuracy: 0.9508\n",
      "Epoch 15/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.9565\n",
      "Epoch 15: accuracy improved from 0.95079 to 0.95655, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 50s 127ms/step - loss: 0.1263 - accuracy: 0.9565\n",
      "Epoch 16/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9603\n",
      "Epoch 16: accuracy improved from 0.95655 to 0.96026, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.1178 - accuracy: 0.9603\n",
      "Epoch 17/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.9635\n",
      "Epoch 17: accuracy improved from 0.96026 to 0.96349, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 49s 125ms/step - loss: 0.1058 - accuracy: 0.9635\n",
      "Epoch 18/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9622\n",
      "Epoch 18: accuracy did not improve from 0.96349\n",
      "390/390 [==============================] - 49s 125ms/step - loss: 0.1086 - accuracy: 0.9622\n",
      "Epoch 19/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1000 - accuracy: 0.9660\n",
      "Epoch 19: accuracy improved from 0.96349 to 0.96597, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 49s 126ms/step - loss: 0.1000 - accuracy: 0.9660\n",
      "Epoch 20/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9666\n",
      "Epoch 20: accuracy improved from 0.96597 to 0.96663, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 49s 126ms/step - loss: 0.0968 - accuracy: 0.9666\n",
      "Epoch 21/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9672\n",
      "Epoch 21: accuracy improved from 0.96663 to 0.96716, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 49s 127ms/step - loss: 0.0966 - accuracy: 0.9672\n",
      "Epoch 22/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9701\n",
      "Epoch 22: accuracy improved from 0.96716 to 0.97008, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 49s 126ms/step - loss: 0.0890 - accuracy: 0.9701\n",
      "Epoch 23/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9696\n",
      "Epoch 23: accuracy did not improve from 0.97008\n",
      "390/390 [==============================] - 49s 126ms/step - loss: 0.0886 - accuracy: 0.9696\n",
      "Epoch 24/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.9710\n",
      "Epoch 24: accuracy improved from 0.97008 to 0.97097, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 50s 128ms/step - loss: 0.0855 - accuracy: 0.9710\n",
      "Epoch 25/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9728\n",
      "Epoch 25: accuracy improved from 0.97097 to 0.97279, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 50s 127ms/step - loss: 0.0794 - accuracy: 0.9728\n",
      "Epoch 26/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9734\n",
      "Epoch 26: accuracy improved from 0.97279 to 0.97339, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 53s 137ms/step - loss: 0.0770 - accuracy: 0.9734\n",
      "Epoch 27/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9732\n",
      "Epoch 27: accuracy did not improve from 0.97339\n",
      "390/390 [==============================] - 50s 128ms/step - loss: 0.0793 - accuracy: 0.9732\n",
      "Epoch 28/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9756\n",
      "Epoch 28: accuracy improved from 0.97339 to 0.97560, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 50s 127ms/step - loss: 0.0714 - accuracy: 0.9756\n",
      "Epoch 29/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9756\n",
      "Epoch 29: accuracy did not improve from 0.97560\n",
      "390/390 [==============================] - 51s 131ms/step - loss: 0.0728 - accuracy: 0.9756\n",
      "Epoch 30/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9766\n",
      "Epoch 30: accuracy improved from 0.97560 to 0.97662, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 50s 128ms/step - loss: 0.0698 - accuracy: 0.9766\n",
      "Epoch 31/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9752\n",
      "Epoch 31: accuracy did not improve from 0.97662\n",
      "390/390 [==============================] - 50s 129ms/step - loss: 0.0746 - accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0697 - accuracy: 0.9770\n",
      "Epoch 32: accuracy improved from 0.97662 to 0.97702, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 49s 124ms/step - loss: 0.0697 - accuracy: 0.9770\n",
      "Epoch 33/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9784\n",
      "Epoch 33: accuracy improved from 0.97702 to 0.97840, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 48s 123ms/step - loss: 0.0650 - accuracy: 0.9784\n",
      "Epoch 34/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9780\n",
      "Epoch 34: accuracy did not improve from 0.97840\n",
      "390/390 [==============================] - 48s 123ms/step - loss: 0.0656 - accuracy: 0.9780\n",
      "Epoch 35/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9772\n",
      "Epoch 35: accuracy did not improve from 0.97840\n",
      "390/390 [==============================] - 48s 123ms/step - loss: 0.0665 - accuracy: 0.9772\n",
      "Epoch 36/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9800\n",
      "Epoch 36: accuracy improved from 0.97840 to 0.98003, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 48s 123ms/step - loss: 0.0617 - accuracy: 0.9800\n",
      "Epoch 37/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9794\n",
      "Epoch 37: accuracy did not improve from 0.98003\n",
      "390/390 [==============================] - 48s 123ms/step - loss: 0.0637 - accuracy: 0.9794\n",
      "Epoch 38/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9802\n",
      "Epoch 38: accuracy improved from 0.98003 to 0.98019, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 47s 121ms/step - loss: 0.0607 - accuracy: 0.9802\n",
      "Epoch 39/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9786\n",
      "Epoch 39: accuracy did not improve from 0.98019\n",
      "390/390 [==============================] - 48s 122ms/step - loss: 0.0633 - accuracy: 0.9786\n",
      "Epoch 40/40\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9817\n",
      "Epoch 40: accuracy improved from 0.98019 to 0.98171, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 47s 122ms/step - loss: 0.0574 - accuracy: 0.9817\n",
      "79/79 [==============================] - 3s 31ms/step - loss: 1.2228 - accuracy: 0.7818\n"
     ]
    }
   ],
   "source": [
    "# Define Callback\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5, verbose=1,  restore_best_weights=True)\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    filepath='cnn_model.h5'\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "model = create_Model1(best_combination[0][0], best_combination[0][1], best_combination[0][2])\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "steps_per_epoch = X_train.shape[0] // batch_size\n",
    "num_epochs = 40\n",
    "\n",
    " # Define Callback\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5, verbose=1,  restore_best_weights=True)\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    filepath='cnn_model.h5'\n",
    ")\n",
    "\n",
    "\n",
    "# Train CNN on the training data\n",
    "r = model.fit(X_train, Y_train, steps_per_epoch=steps_per_epoch, epochs = num_epochs, batch_size=batch_size, callbacks=[checkpoint_callback, callback])\n",
    "\n",
    "# Load the best model\n",
    "best_model = load_model('cnn_model.h5')\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy:  0.7817999720573425\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Model2(k, dr, lr):\n",
    "    \n",
    "    i = Input(shape = (32, 32, 3))\n",
    "\n",
    "    x = Conv2D(32, (k,k), activation= 'relu', padding='same')(i)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, (k,k), activation= 'relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Dropout(dr)(x)\n",
    "\n",
    "    x = Conv2D(64, (k,k), activation= 'relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (k,k), activation= 'relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Dropout(dr)(x)\n",
    "    \n",
    "    x = Conv2D(128, (k,k), activation= 'relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (k,k), activation= 'relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Dropout(dr)(x)\n",
    "    \n",
    "    x = Conv2D(256, (k,k), activation= 'relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(256, (k,k), activation= 'relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Dropout(dr)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(dr)(x)\n",
    "\n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "    \n",
    "\n",
    "    model = Model(i,x)\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate = lr)\n",
    "    \n",
    "    model.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model summary with filter size as 3x3, dropout rate as 0.20 and learning rate as 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 16, 16, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 8, 8, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 8, 8, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 4, 4, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 4, 4, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 2, 2, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2235946 (8.53 MB)\n",
      "Trainable params: 2234026 (8.52 MB)\n",
      "Non-trainable params: 1920 (7.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create_Model2(3, 0.20, 0.01).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top three combinations from experiment 1 in descending order:  [(3, 0.2, 0.001), (5, 0.35, 0.001), (5, 0.2, 0.001)]\n"
     ]
    }
   ],
   "source": [
    "# Get the three combinations that performed the best in experiment 1\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for key, value in results.items():\n",
    "    if 'accuracy' in value:\n",
    "        accuracies.append((key, value['accuracy']))\n",
    "\n",
    "accuracies.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "combinations = [item[0] for item in accuracies[:5]]\n",
    "\n",
    "print(\"The top three combinations from experiment 1 in descending order: \", combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for combination in combinations:\n",
    "    results[combination[0], combination[1], combination[2]] = {'accuracy': 0,  'loss': 0, 'history': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_combination = [ [0, 0, 0], [0, 0, None] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COMBINATION: filter_size=3, dropout_rate=0.2, learning_rate=0.001\n",
      "Epoch 1/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.8504 - accuracy: 0.3573\n",
      "Epoch 1: val_accuracy improved from -inf to 0.16420, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 69s 210ms/step - loss: 1.8504 - accuracy: 0.3573 - val_loss: 3.4646 - val_accuracy: 0.1642\n",
      "Epoch 2/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3902 - accuracy: 0.4960\n",
      "Epoch 2: val_accuracy improved from 0.16420 to 0.56540, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 1.3902 - accuracy: 0.4960 - val_loss: 1.2422 - val_accuracy: 0.5654\n",
      "Epoch 3/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1942 - accuracy: 0.5734\n",
      "Epoch 3: val_accuracy improved from 0.56540 to 0.60170, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 70s 223ms/step - loss: 1.1942 - accuracy: 0.5734 - val_loss: 1.1690 - val_accuracy: 0.6017\n",
      "Epoch 4/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0440 - accuracy: 0.6333\n",
      "Epoch 4: val_accuracy did not improve from 0.60170\n",
      "312/312 [==============================] - 65s 209ms/step - loss: 1.0440 - accuracy: 0.6333 - val_loss: 1.6519 - val_accuracy: 0.5525\n",
      "Epoch 5/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9413 - accuracy: 0.6696\n",
      "Epoch 5: val_accuracy improved from 0.60170 to 0.66150, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 65s 207ms/step - loss: 0.9413 - accuracy: 0.6696 - val_loss: 1.0288 - val_accuracy: 0.6615\n",
      "Epoch 6/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8675 - accuracy: 0.6991\n",
      "Epoch 6: val_accuracy improved from 0.66150 to 0.70590, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 66s 212ms/step - loss: 0.8675 - accuracy: 0.6991 - val_loss: 0.8622 - val_accuracy: 0.7059\n",
      "Epoch 7/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8162 - accuracy: 0.7162\n",
      "Epoch 7: val_accuracy improved from 0.70590 to 0.72400, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 67s 214ms/step - loss: 0.8162 - accuracy: 0.7162 - val_loss: 0.8151 - val_accuracy: 0.7240\n",
      "Epoch 8/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7677 - accuracy: 0.7350\n",
      "Epoch 8: val_accuracy did not improve from 0.72400\n",
      "312/312 [==============================] - 67s 214ms/step - loss: 0.7677 - accuracy: 0.7350 - val_loss: 0.8054 - val_accuracy: 0.7232\n",
      "Epoch 9/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7346 - accuracy: 0.7479\n",
      "Epoch 9: val_accuracy did not improve from 0.72400\n",
      "312/312 [==============================] - 64s 205ms/step - loss: 0.7346 - accuracy: 0.7479 - val_loss: 0.8724 - val_accuracy: 0.7066\n",
      "Epoch 10/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7043 - accuracy: 0.7581\n",
      "Epoch 10: val_accuracy improved from 0.72400 to 0.74780, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 68s 218ms/step - loss: 0.7043 - accuracy: 0.7581 - val_loss: 0.7571 - val_accuracy: 0.7478\n",
      "Epoch 11/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6801 - accuracy: 0.7670\n",
      "Epoch 11: val_accuracy improved from 0.74780 to 0.75840, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 69s 222ms/step - loss: 0.6801 - accuracy: 0.7670 - val_loss: 0.7208 - val_accuracy: 0.7584\n",
      "Epoch 12/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6575 - accuracy: 0.7740\n",
      "Epoch 12: val_accuracy improved from 0.75840 to 0.76830, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 68s 219ms/step - loss: 0.6575 - accuracy: 0.7740 - val_loss: 0.6983 - val_accuracy: 0.7683\n",
      "Epoch 13/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6293 - accuracy: 0.7834\n",
      "Epoch 13: val_accuracy did not improve from 0.76830\n",
      "312/312 [==============================] - 69s 219ms/step - loss: 0.6293 - accuracy: 0.7834 - val_loss: 0.8394 - val_accuracy: 0.7343\n",
      "Epoch 14/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6128 - accuracy: 0.7880\n",
      "Epoch 14: val_accuracy improved from 0.76830 to 0.77920, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 76s 243ms/step - loss: 0.6128 - accuracy: 0.7880 - val_loss: 0.6484 - val_accuracy: 0.7792\n",
      "Epoch 15/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5921 - accuracy: 0.7969\n",
      "Epoch 15: val_accuracy improved from 0.77920 to 0.78960, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 75s 241ms/step - loss: 0.5921 - accuracy: 0.7969 - val_loss: 0.6507 - val_accuracy: 0.7896\n",
      "Epoch 16/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5750 - accuracy: 0.8013\n",
      "Epoch 16: val_accuracy improved from 0.78960 to 0.81630, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 72s 231ms/step - loss: 0.5750 - accuracy: 0.8013 - val_loss: 0.5378 - val_accuracy: 0.8163\n",
      "Epoch 17/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5659 - accuracy: 0.8063\n",
      "Epoch 17: val_accuracy improved from 0.81630 to 0.82350, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 71s 226ms/step - loss: 0.5659 - accuracy: 0.8063 - val_loss: 0.5221 - val_accuracy: 0.8235\n",
      "Epoch 18/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5531 - accuracy: 0.8114\n",
      "Epoch 18: val_accuracy did not improve from 0.82350\n",
      "312/312 [==============================] - 66s 213ms/step - loss: 0.5531 - accuracy: 0.8114 - val_loss: 0.7026 - val_accuracy: 0.7700\n",
      "Epoch 19/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5460 - accuracy: 0.8119\n",
      "Epoch 19: val_accuracy improved from 0.82350 to 0.82740, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 67s 213ms/step - loss: 0.5460 - accuracy: 0.8119 - val_loss: 0.5087 - val_accuracy: 0.8274\n",
      "Epoch 20/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5282 - accuracy: 0.8190\n",
      "Epoch 20: val_accuracy did not improve from 0.82740\n",
      "312/312 [==============================] - 68s 217ms/step - loss: 0.5282 - accuracy: 0.8190 - val_loss: 0.5769 - val_accuracy: 0.8070\n",
      "Epoch 21/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5114 - accuracy: 0.8250\n",
      "Epoch 21: val_accuracy did not improve from 0.82740\n",
      "312/312 [==============================] - 67s 213ms/step - loss: 0.5114 - accuracy: 0.8250 - val_loss: 0.6190 - val_accuracy: 0.7977\n",
      "Epoch 22/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.8244\n",
      "Epoch 22: val_accuracy did not improve from 0.82740\n",
      "312/312 [==============================] - 73s 233ms/step - loss: 0.5057 - accuracy: 0.8244 - val_loss: 0.6120 - val_accuracy: 0.8019\n",
      "Epoch 23/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4987 - accuracy: 0.8314\n",
      "Epoch 23: val_accuracy improved from 0.82740 to 0.83450, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 69s 220ms/step - loss: 0.4987 - accuracy: 0.8314 - val_loss: 0.4932 - val_accuracy: 0.8345\n",
      "Epoch 24/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4881 - accuracy: 0.8322\n",
      "Epoch 24: val_accuracy did not improve from 0.83450\n",
      "312/312 [==============================] - 66s 210ms/step - loss: 0.4881 - accuracy: 0.8322 - val_loss: 0.6020 - val_accuracy: 0.8030\n",
      "Epoch 25/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4751 - accuracy: 0.8348\n",
      "Epoch 25: val_accuracy did not improve from 0.83450\n",
      "312/312 [==============================] - 68s 219ms/step - loss: 0.4751 - accuracy: 0.8348 - val_loss: 0.5058 - val_accuracy: 0.8320\n",
      "Epoch 26/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4659 - accuracy: 0.8372\n",
      "Epoch 26: val_accuracy did not improve from 0.83450\n",
      "312/312 [==============================] - 72s 232ms/step - loss: 0.4659 - accuracy: 0.8372 - val_loss: 0.5044 - val_accuracy: 0.8322\n",
      "Epoch 27/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4598 - accuracy: 0.8426\n",
      "Epoch 27: val_accuracy did not improve from 0.83450\n",
      "312/312 [==============================] - 81s 261ms/step - loss: 0.4598 - accuracy: 0.8426 - val_loss: 0.5319 - val_accuracy: 0.8269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4555 - accuracy: 0.8422\n",
      "Epoch 28: val_accuracy improved from 0.83450 to 0.86670, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 101s 324ms/step - loss: 0.4555 - accuracy: 0.8422 - val_loss: 0.4050 - val_accuracy: 0.8667\n",
      "Epoch 29/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4481 - accuracy: 0.8447\n",
      "Epoch 29: val_accuracy did not improve from 0.86670\n",
      "312/312 [==============================] - 110s 353ms/step - loss: 0.4481 - accuracy: 0.8447 - val_loss: 0.4741 - val_accuracy: 0.8409\n",
      "Epoch 30/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4411 - accuracy: 0.8474\n",
      "Epoch 30: val_accuracy did not improve from 0.86670\n",
      "312/312 [==============================] - 112s 358ms/step - loss: 0.4411 - accuracy: 0.8474 - val_loss: 0.4515 - val_accuracy: 0.8502\n",
      "Epoch 31/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4264 - accuracy: 0.8528\n",
      "Epoch 31: val_accuracy did not improve from 0.86670\n",
      "312/312 [==============================] - 103s 329ms/step - loss: 0.4264 - accuracy: 0.8528 - val_loss: 0.4141 - val_accuracy: 0.8605\n",
      "Epoch 32/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4302 - accuracy: 0.8521\n",
      "Epoch 32: val_accuracy did not improve from 0.86670\n",
      "312/312 [==============================] - 108s 347ms/step - loss: 0.4302 - accuracy: 0.8521 - val_loss: 0.5579 - val_accuracy: 0.8186\n",
      "Epoch 33/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4191 - accuracy: 0.8552\n",
      "Epoch 33: val_accuracy did not improve from 0.86670\n",
      "312/312 [==============================] - 107s 342ms/step - loss: 0.4191 - accuracy: 0.8552 - val_loss: 0.4665 - val_accuracy: 0.8466\n",
      "Epoch 34/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4157 - accuracy: 0.8550\n",
      "Epoch 34: val_accuracy did not improve from 0.86670\n",
      "312/312 [==============================] - 103s 328ms/step - loss: 0.4157 - accuracy: 0.8550 - val_loss: 0.4855 - val_accuracy: 0.8384\n",
      "Epoch 35/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4131 - accuracy: 0.8563\n",
      "Epoch 35: val_accuracy did not improve from 0.86670\n",
      "312/312 [==============================] - 108s 344ms/step - loss: 0.4131 - accuracy: 0.8563 - val_loss: 0.5003 - val_accuracy: 0.8410\n",
      "Epoch 36/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4070 - accuracy: 0.8602\n",
      "Epoch 36: val_accuracy did not improve from 0.86670\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "312/312 [==============================] - 82s 263ms/step - loss: 0.4070 - accuracy: 0.8602 - val_loss: 0.4412 - val_accuracy: 0.8565\n",
      "Epoch 36: early stopping\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.4050 - accuracy: 0.8667\n",
      "COMBINATION BEST ACCURACY:  0.8666999936103821\n",
      "\n",
      "COMBINATION: filter_size=5, dropout_rate=0.35, learning_rate=0.001\n",
      "Epoch 1/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.9675 - accuracy: 0.3113\n",
      "Epoch 1: val_accuracy improved from -inf to 0.11130, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 176s 556ms/step - loss: 1.9675 - accuracy: 0.3113 - val_loss: 3.6711 - val_accuracy: 0.1113\n",
      "Epoch 2/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.5088 - accuracy: 0.4555\n",
      "Epoch 2: val_accuracy improved from 0.11130 to 0.42780, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 174s 559ms/step - loss: 1.5088 - accuracy: 0.4555 - val_loss: 1.7553 - val_accuracy: 0.4278\n",
      "Epoch 3/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3213 - accuracy: 0.5336\n",
      "Epoch 3: val_accuracy improved from 0.42780 to 0.48330, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 174s 556ms/step - loss: 1.3213 - accuracy: 0.5336 - val_loss: 1.6689 - val_accuracy: 0.4833\n",
      "Epoch 4/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1736 - accuracy: 0.5876\n",
      "Epoch 4: val_accuracy improved from 0.48330 to 0.61470, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 172s 552ms/step - loss: 1.1736 - accuracy: 0.5876 - val_loss: 1.1548 - val_accuracy: 0.6147\n",
      "Epoch 5/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0593 - accuracy: 0.6325\n",
      "Epoch 5: val_accuracy improved from 0.61470 to 0.61510, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 173s 555ms/step - loss: 1.0593 - accuracy: 0.6325 - val_loss: 1.2190 - val_accuracy: 0.6151\n",
      "Epoch 6/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9876 - accuracy: 0.6594\n",
      "Epoch 6: val_accuracy improved from 0.61510 to 0.67820, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 172s 550ms/step - loss: 0.9876 - accuracy: 0.6594 - val_loss: 0.9201 - val_accuracy: 0.6782\n",
      "Epoch 7/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9183 - accuracy: 0.6839\n",
      "Epoch 7: val_accuracy did not improve from 0.67820\n",
      "312/312 [==============================] - 167s 537ms/step - loss: 0.9183 - accuracy: 0.6839 - val_loss: 1.1577 - val_accuracy: 0.6263\n",
      "Epoch 8/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8799 - accuracy: 0.7008\n",
      "Epoch 8: val_accuracy improved from 0.67820 to 0.74430, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 174s 557ms/step - loss: 0.8799 - accuracy: 0.7008 - val_loss: 0.7651 - val_accuracy: 0.7443\n",
      "Epoch 9/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8343 - accuracy: 0.7180\n",
      "Epoch 9: val_accuracy did not improve from 0.74430\n",
      "312/312 [==============================] - 179s 572ms/step - loss: 0.8343 - accuracy: 0.7180 - val_loss: 0.8029 - val_accuracy: 0.7416\n",
      "Epoch 10/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7965 - accuracy: 0.7289\n",
      "Epoch 10: val_accuracy improved from 0.74430 to 0.74720, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 169s 542ms/step - loss: 0.7965 - accuracy: 0.7289 - val_loss: 0.7365 - val_accuracy: 0.7472\n",
      "Epoch 11/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7635 - accuracy: 0.7426\n",
      "Epoch 11: val_accuracy improved from 0.74720 to 0.75160, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 171s 547ms/step - loss: 0.7635 - accuracy: 0.7426 - val_loss: 0.7365 - val_accuracy: 0.7516\n",
      "Epoch 12/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7342 - accuracy: 0.7498\n",
      "Epoch 12: val_accuracy improved from 0.75160 to 0.75640, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 179s 573ms/step - loss: 0.7342 - accuracy: 0.7498 - val_loss: 0.7162 - val_accuracy: 0.7564\n",
      "Epoch 13/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7164 - accuracy: 0.7561\n",
      "Epoch 13: val_accuracy improved from 0.75640 to 0.75920, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 178s 570ms/step - loss: 0.7164 - accuracy: 0.7561 - val_loss: 0.7088 - val_accuracy: 0.7592\n",
      "Epoch 14/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.7645\n",
      "Epoch 14: val_accuracy improved from 0.75920 to 0.77600, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 176s 564ms/step - loss: 0.6953 - accuracy: 0.7645 - val_loss: 0.6468 - val_accuracy: 0.7760\n",
      "Epoch 15/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6673 - accuracy: 0.7753\n",
      "Epoch 15: val_accuracy improved from 0.77600 to 0.79900, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 180s 575ms/step - loss: 0.6673 - accuracy: 0.7753 - val_loss: 0.6178 - val_accuracy: 0.7990\n",
      "Epoch 16/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6618 - accuracy: 0.7777\n",
      "Epoch 16: val_accuracy did not improve from 0.79900\n",
      "312/312 [==============================] - 170s 543ms/step - loss: 0.6618 - accuracy: 0.7777 - val_loss: 0.7336 - val_accuracy: 0.7611\n",
      "Epoch 17/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6453 - accuracy: 0.7821\n",
      "Epoch 17: val_accuracy did not improve from 0.79900\n",
      "312/312 [==============================] - 179s 575ms/step - loss: 0.6453 - accuracy: 0.7821 - val_loss: 0.7059 - val_accuracy: 0.7705\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - ETA: 0s - loss: 0.6352 - accuracy: 0.7868\n",
      "Epoch 18: val_accuracy did not improve from 0.79900\n",
      "312/312 [==============================] - 176s 565ms/step - loss: 0.6352 - accuracy: 0.7868 - val_loss: 0.6347 - val_accuracy: 0.7909\n",
      "Epoch 19/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6042 - accuracy: 0.7938\n",
      "Epoch 19: val_accuracy improved from 0.79900 to 0.82340, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 173s 553ms/step - loss: 0.6042 - accuracy: 0.7938 - val_loss: 0.5175 - val_accuracy: 0.8234\n",
      "Epoch 20/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5990 - accuracy: 0.7973\n",
      "Epoch 20: val_accuracy did not improve from 0.82340\n",
      "312/312 [==============================] - 171s 547ms/step - loss: 0.5990 - accuracy: 0.7973 - val_loss: 0.7271 - val_accuracy: 0.7670\n",
      "Epoch 21/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5897 - accuracy: 0.8024\n",
      "Epoch 21: val_accuracy did not improve from 0.82340\n",
      "312/312 [==============================] - 170s 545ms/step - loss: 0.5897 - accuracy: 0.8024 - val_loss: 0.5681 - val_accuracy: 0.8071\n",
      "Epoch 22/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5763 - accuracy: 0.8058\n",
      "Epoch 22: val_accuracy did not improve from 0.82340\n",
      "312/312 [==============================] - 172s 551ms/step - loss: 0.5763 - accuracy: 0.8058 - val_loss: 0.6543 - val_accuracy: 0.7910\n",
      "Epoch 23/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5681 - accuracy: 0.8053\n",
      "Epoch 23: val_accuracy did not improve from 0.82340\n",
      "312/312 [==============================] - 174s 557ms/step - loss: 0.5681 - accuracy: 0.8053 - val_loss: 0.5695 - val_accuracy: 0.8073\n",
      "Epoch 24/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5529 - accuracy: 0.8123\n",
      "Epoch 24: val_accuracy did not improve from 0.82340\n",
      "312/312 [==============================] - 175s 561ms/step - loss: 0.5529 - accuracy: 0.8123 - val_loss: 0.5919 - val_accuracy: 0.8038\n",
      "Epoch 25/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5576 - accuracy: 0.8120\n",
      "Epoch 25: val_accuracy did not improve from 0.82340\n",
      "312/312 [==============================] - 176s 564ms/step - loss: 0.5576 - accuracy: 0.8120 - val_loss: 0.5885 - val_accuracy: 0.8049\n",
      "Epoch 26/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5356 - accuracy: 0.8186\n",
      "Epoch 26: val_accuracy improved from 0.82340 to 0.83400, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 171s 547ms/step - loss: 0.5356 - accuracy: 0.8186 - val_loss: 0.4917 - val_accuracy: 0.8340\n",
      "Epoch 27/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5322 - accuracy: 0.8209\n",
      "Epoch 27: val_accuracy did not improve from 0.83400\n",
      "312/312 [==============================] - 171s 549ms/step - loss: 0.5322 - accuracy: 0.8209 - val_loss: 0.5510 - val_accuracy: 0.8153\n",
      "Epoch 28/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5203 - accuracy: 0.8238\n",
      "Epoch 28: val_accuracy did not improve from 0.83400\n",
      "312/312 [==============================] - 176s 563ms/step - loss: 0.5203 - accuracy: 0.8238 - val_loss: 0.5435 - val_accuracy: 0.8135\n",
      "Epoch 29/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.8235\n",
      "Epoch 29: val_accuracy did not improve from 0.83400\n",
      "312/312 [==============================] - 175s 559ms/step - loss: 0.5182 - accuracy: 0.8235 - val_loss: 0.7723 - val_accuracy: 0.7482\n",
      "Epoch 30/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5121 - accuracy: 0.8263\n",
      "Epoch 30: val_accuracy improved from 0.83400 to 0.83860, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 173s 554ms/step - loss: 0.5121 - accuracy: 0.8263 - val_loss: 0.4969 - val_accuracy: 0.8386\n",
      "Epoch 31/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4967 - accuracy: 0.8316\n",
      "Epoch 31: val_accuracy did not improve from 0.83860\n",
      "312/312 [==============================] - 175s 559ms/step - loss: 0.4967 - accuracy: 0.8316 - val_loss: 0.4894 - val_accuracy: 0.8378\n",
      "Epoch 32/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4945 - accuracy: 0.8332\n",
      "Epoch 32: val_accuracy did not improve from 0.83860\n",
      "312/312 [==============================] - 178s 569ms/step - loss: 0.4945 - accuracy: 0.8332 - val_loss: 0.5113 - val_accuracy: 0.8259\n",
      "Epoch 33/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4949 - accuracy: 0.8330\n",
      "Epoch 33: val_accuracy did not improve from 0.83860\n",
      "312/312 [==============================] - 170s 544ms/step - loss: 0.4949 - accuracy: 0.8330 - val_loss: 0.6216 - val_accuracy: 0.8045\n",
      "Epoch 34/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4797 - accuracy: 0.8370\n",
      "Epoch 34: val_accuracy improved from 0.83860 to 0.84790, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 173s 553ms/step - loss: 0.4797 - accuracy: 0.8370 - val_loss: 0.4508 - val_accuracy: 0.8479\n",
      "Epoch 35/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4887 - accuracy: 0.8324\n",
      "Epoch 35: val_accuracy did not improve from 0.84790\n",
      "312/312 [==============================] - 181s 581ms/step - loss: 0.4887 - accuracy: 0.8324 - val_loss: 0.4825 - val_accuracy: 0.8390\n",
      "Epoch 36/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 0.8396\n",
      "Epoch 36: val_accuracy did not improve from 0.84790\n",
      "312/312 [==============================] - 179s 574ms/step - loss: 0.4696 - accuracy: 0.8396 - val_loss: 0.5514 - val_accuracy: 0.8183\n",
      "Epoch 37/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4802 - accuracy: 0.8362\n",
      "Epoch 37: val_accuracy did not improve from 0.84790\n",
      "312/312 [==============================] - 177s 567ms/step - loss: 0.4802 - accuracy: 0.8362 - val_loss: 0.4896 - val_accuracy: 0.8344\n",
      "Epoch 38/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4751 - accuracy: 0.8400\n",
      "Epoch 38: val_accuracy did not improve from 0.84790\n",
      "312/312 [==============================] - 178s 572ms/step - loss: 0.4751 - accuracy: 0.8400 - val_loss: 0.5264 - val_accuracy: 0.8267\n",
      "Epoch 39/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4582 - accuracy: 0.8438\n",
      "Epoch 39: val_accuracy did not improve from 0.84790\n",
      "312/312 [==============================] - 180s 578ms/step - loss: 0.4582 - accuracy: 0.8438 - val_loss: 0.5104 - val_accuracy: 0.8325\n",
      "Epoch 40/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.8498\n",
      "Epoch 40: val_accuracy did not improve from 0.84790\n",
      "312/312 [==============================] - 176s 563ms/step - loss: 0.4396 - accuracy: 0.8498 - val_loss: 0.4634 - val_accuracy: 0.8448\n",
      "Epoch 41/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4384 - accuracy: 0.8481\n",
      "Epoch 41: val_accuracy did not improve from 0.84790\n",
      "312/312 [==============================] - 180s 578ms/step - loss: 0.4384 - accuracy: 0.8481 - val_loss: 0.4894 - val_accuracy: 0.8386\n",
      "Epoch 42/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4483 - accuracy: 0.8477\n",
      "Epoch 42: val_accuracy improved from 0.84790 to 0.85980, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 174s 559ms/step - loss: 0.4483 - accuracy: 0.8477 - val_loss: 0.4357 - val_accuracy: 0.8598\n",
      "Epoch 43/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.8526\n",
      "Epoch 43: val_accuracy did not improve from 0.85980\n",
      "312/312 [==============================] - 164s 524ms/step - loss: 0.4366 - accuracy: 0.8526 - val_loss: 0.4634 - val_accuracy: 0.8456\n",
      "Epoch 44/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4292 - accuracy: 0.8528\n",
      "Epoch 44: val_accuracy did not improve from 0.85980\n",
      "312/312 [==============================] - 168s 538ms/step - loss: 0.4292 - accuracy: 0.8528 - val_loss: 0.4843 - val_accuracy: 0.8415\n",
      "Epoch 45/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4300 - accuracy: 0.8506\n",
      "Epoch 45: val_accuracy did not improve from 0.85980\n",
      "312/312 [==============================] - 170s 543ms/step - loss: 0.4300 - accuracy: 0.8506 - val_loss: 0.5471 - val_accuracy: 0.8197\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - ETA: 0s - loss: 0.4267 - accuracy: 0.8533\n",
      "Epoch 46: val_accuracy did not improve from 0.85980\n",
      "312/312 [==============================] - 172s 549ms/step - loss: 0.4267 - accuracy: 0.8533 - val_loss: 0.4664 - val_accuracy: 0.8434\n",
      "Epoch 47/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4231 - accuracy: 0.8567\n",
      "Epoch 47: val_accuracy did not improve from 0.85980\n",
      "312/312 [==============================] - 169s 540ms/step - loss: 0.4231 - accuracy: 0.8567 - val_loss: 0.4818 - val_accuracy: 0.8415\n",
      "Epoch 48/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4257 - accuracy: 0.8542\n",
      "Epoch 48: val_accuracy did not improve from 0.85980\n",
      "312/312 [==============================] - 166s 533ms/step - loss: 0.4257 - accuracy: 0.8542 - val_loss: 0.4094 - val_accuracy: 0.8585\n",
      "Epoch 49/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4285 - accuracy: 0.8529\n",
      "Epoch 49: val_accuracy did not improve from 0.85980\n",
      "312/312 [==============================] - 172s 552ms/step - loss: 0.4285 - accuracy: 0.8529 - val_loss: 1.6121 - val_accuracy: 0.6348\n",
      "Epoch 50/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4433 - accuracy: 0.8477\n",
      "Epoch 50: val_accuracy did not improve from 0.85980\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "312/312 [==============================] - 176s 564ms/step - loss: 0.4433 - accuracy: 0.8477 - val_loss: 0.5126 - val_accuracy: 0.8344\n",
      "Epoch 50: early stopping\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.4357 - accuracy: 0.8598\n",
      "COMBINATION BEST ACCURACY:  0.8597999811172485\n",
      "\n",
      "COMBINATION: filter_size=5, dropout_rate=0.2, learning_rate=0.001\n",
      "Epoch 1/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.8675 - accuracy: 0.3484\n",
      "Epoch 1: val_accuracy improved from -inf to 0.21660, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 185s 586ms/step - loss: 1.8675 - accuracy: 0.3484 - val_loss: 2.5547 - val_accuracy: 0.2166\n",
      "Epoch 2/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.3900 - accuracy: 0.5028\n",
      "Epoch 2: val_accuracy improved from 0.21660 to 0.53280, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 178s 571ms/step - loss: 1.3900 - accuracy: 0.5028 - val_loss: 1.3281 - val_accuracy: 0.5328\n",
      "Epoch 3/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.1588 - accuracy: 0.5925\n",
      "Epoch 3: val_accuracy did not improve from 0.53280\n",
      "312/312 [==============================] - 179s 573ms/step - loss: 1.1588 - accuracy: 0.5925 - val_loss: 1.5662 - val_accuracy: 0.5154\n",
      "Epoch 4/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 1.0061 - accuracy: 0.6490\n",
      "Epoch 4: val_accuracy improved from 0.53280 to 0.66990, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 180s 576ms/step - loss: 1.0061 - accuracy: 0.6490 - val_loss: 0.9444 - val_accuracy: 0.6699\n",
      "Epoch 5/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.9134 - accuracy: 0.6856\n",
      "Epoch 5: val_accuracy improved from 0.66990 to 0.70020, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 177s 567ms/step - loss: 0.9134 - accuracy: 0.6856 - val_loss: 0.8754 - val_accuracy: 0.7002\n",
      "Epoch 6/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.8382 - accuracy: 0.7118\n",
      "Epoch 6: val_accuracy improved from 0.70020 to 0.71320, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 173s 553ms/step - loss: 0.8382 - accuracy: 0.7118 - val_loss: 0.8240 - val_accuracy: 0.7132\n",
      "Epoch 7/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7941 - accuracy: 0.7279\n",
      "Epoch 7: val_accuracy improved from 0.71320 to 0.73710, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 181s 579ms/step - loss: 0.7941 - accuracy: 0.7279 - val_loss: 0.7705 - val_accuracy: 0.7371\n",
      "Epoch 8/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7531 - accuracy: 0.7440\n",
      "Epoch 8: val_accuracy did not improve from 0.73710\n",
      "312/312 [==============================] - 168s 538ms/step - loss: 0.7531 - accuracy: 0.7440 - val_loss: 0.9530 - val_accuracy: 0.6937\n",
      "Epoch 9/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.7125 - accuracy: 0.7579\n",
      "Epoch 9: val_accuracy improved from 0.73710 to 0.74100, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 178s 570ms/step - loss: 0.7125 - accuracy: 0.7579 - val_loss: 0.7820 - val_accuracy: 0.7410\n",
      "Epoch 10/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6707 - accuracy: 0.7714\n",
      "Epoch 10: val_accuracy improved from 0.74100 to 0.77290, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 180s 578ms/step - loss: 0.6707 - accuracy: 0.7714 - val_loss: 0.6636 - val_accuracy: 0.7729\n",
      "Epoch 11/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6423 - accuracy: 0.7809\n",
      "Epoch 11: val_accuracy improved from 0.77290 to 0.79370, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 180s 577ms/step - loss: 0.6423 - accuracy: 0.7809 - val_loss: 0.6065 - val_accuracy: 0.7937\n",
      "Epoch 12/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6150 - accuracy: 0.7901\n",
      "Epoch 12: val_accuracy did not improve from 0.79370\n",
      "312/312 [==============================] - 171s 546ms/step - loss: 0.6150 - accuracy: 0.7901 - val_loss: 0.7612 - val_accuracy: 0.7457\n",
      "Epoch 13/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5956 - accuracy: 0.7938\n",
      "Epoch 13: val_accuracy did not improve from 0.79370\n",
      "312/312 [==============================] - 177s 566ms/step - loss: 0.5956 - accuracy: 0.7938 - val_loss: 0.6515 - val_accuracy: 0.7838\n",
      "Epoch 14/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5803 - accuracy: 0.8020\n",
      "Epoch 14: val_accuracy improved from 0.79370 to 0.80640, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 172s 550ms/step - loss: 0.5803 - accuracy: 0.8020 - val_loss: 0.5649 - val_accuracy: 0.8064\n",
      "Epoch 15/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5754 - accuracy: 0.8047\n",
      "Epoch 15: val_accuracy did not improve from 0.80640\n",
      "312/312 [==============================] - 164s 526ms/step - loss: 0.5754 - accuracy: 0.8047 - val_loss: 0.5984 - val_accuracy: 0.7998\n",
      "Epoch 16/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5419 - accuracy: 0.8145\n",
      "Epoch 16: val_accuracy did not improve from 0.80640\n",
      "312/312 [==============================] - 168s 539ms/step - loss: 0.5419 - accuracy: 0.8145 - val_loss: 0.6234 - val_accuracy: 0.7964\n",
      "Epoch 17/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5385 - accuracy: 0.8175\n",
      "Epoch 17: val_accuracy did not improve from 0.80640\n",
      "312/312 [==============================] - 165s 527ms/step - loss: 0.5385 - accuracy: 0.8175 - val_loss: 0.7627 - val_accuracy: 0.7618\n",
      "Epoch 18/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5385 - accuracy: 0.8179\n",
      "Epoch 18: val_accuracy did not improve from 0.80640\n",
      "312/312 [==============================] - 173s 556ms/step - loss: 0.5385 - accuracy: 0.8179 - val_loss: 0.6050 - val_accuracy: 0.7946\n",
      "Epoch 19/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.8253\n",
      "Epoch 19: val_accuracy did not improve from 0.80640\n",
      "312/312 [==============================] - 177s 568ms/step - loss: 0.5185 - accuracy: 0.8253 - val_loss: 0.6171 - val_accuracy: 0.7959\n",
      "Epoch 20/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4994 - accuracy: 0.8305\n",
      "Epoch 20: val_accuracy did not improve from 0.80640\n",
      "312/312 [==============================] - 180s 577ms/step - loss: 0.4994 - accuracy: 0.8305 - val_loss: 0.6937 - val_accuracy: 0.7682\n",
      "Epoch 21/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4973 - accuracy: 0.8321\n",
      "Epoch 21: val_accuracy improved from 0.80640 to 0.83880, saving model to cnn_model.h5\n",
      "312/312 [==============================] - 166s 532ms/step - loss: 0.4973 - accuracy: 0.8321 - val_loss: 0.4791 - val_accuracy: 0.8388\n",
      "Epoch 22/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4958 - accuracy: 0.8341\n",
      "Epoch 22: val_accuracy did not improve from 0.83880\n",
      "312/312 [==============================] - 165s 528ms/step - loss: 0.4958 - accuracy: 0.8341 - val_loss: 0.6050 - val_accuracy: 0.8043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4655 - accuracy: 0.8402\n",
      "Epoch 23: val_accuracy did not improve from 0.83880\n",
      "312/312 [==============================] - 163s 523ms/step - loss: 0.4655 - accuracy: 0.8402 - val_loss: 0.6291 - val_accuracy: 0.7965\n",
      "Epoch 24/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.6103 - accuracy: 0.7970\n",
      "Epoch 24: val_accuracy did not improve from 0.83880\n",
      "312/312 [==============================] - 162s 519ms/step - loss: 0.6103 - accuracy: 0.7970 - val_loss: 0.5981 - val_accuracy: 0.7991\n",
      "Epoch 25/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5059 - accuracy: 0.8261\n",
      "Epoch 25: val_accuracy did not improve from 0.83880\n",
      "312/312 [==============================] - 162s 520ms/step - loss: 0.5059 - accuracy: 0.8261 - val_loss: 0.5135 - val_accuracy: 0.8225\n",
      "Epoch 26/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.5066 - accuracy: 0.8309\n",
      "Epoch 26: val_accuracy did not improve from 0.83880\n",
      "312/312 [==============================] - 162s 520ms/step - loss: 0.5066 - accuracy: 0.8309 - val_loss: 0.9407 - val_accuracy: 0.7035\n",
      "Epoch 27/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4682 - accuracy: 0.8389\n",
      "Epoch 27: val_accuracy did not improve from 0.83880\n",
      "312/312 [==============================] - 162s 519ms/step - loss: 0.4682 - accuracy: 0.8389 - val_loss: 0.5439 - val_accuracy: 0.8219\n",
      "Epoch 28/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.8488\n",
      "Epoch 28: val_accuracy did not improve from 0.83880\n",
      "312/312 [==============================] - 165s 528ms/step - loss: 0.4399 - accuracy: 0.8488 - val_loss: 0.6561 - val_accuracy: 0.7826\n",
      "Epoch 29/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.8509\n",
      "Epoch 29: val_accuracy did not improve from 0.83880\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "312/312 [==============================] - 163s 523ms/step - loss: 0.4333 - accuracy: 0.8509 - val_loss: 0.5095 - val_accuracy: 0.8367\n",
      "Epoch 29: early stopping\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.4791 - accuracy: 0.8388\n",
      "COMBINATION BEST ACCURACY:  0.8388000130653381\n"
     ]
    }
   ],
   "source": [
    "for combination in combinations:\n",
    "            \n",
    "    print(\"\\n\" + f\"COMBINATION: filter_size={combination[0]}, dropout_rate={combination[1]}, learning_rate={combination[2]}\")\n",
    "\n",
    "    # Initialise batch size, steps per epoch, number of epochs\n",
    "    batch_size = 128\n",
    "    steps_per_epoch = X_train_set.shape[0] // batch_size\n",
    "    num_epochs = 50\n",
    "\n",
    "     # Define Callback\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=8, verbose=1,  restore_best_weights=True)\n",
    "\n",
    "    # Define the ModelCheckpoint callback\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1,\n",
    "        filepath='cnn_model.h5'\n",
    "    )\n",
    "\n",
    "    # Build the model\n",
    "    model = create_Model2(combination[0], combination[1], combination[2])\n",
    "\n",
    "    # Train CNN on the training data\n",
    "    r = model.fit(train_generator, validation_data=(X_val, Y_val), steps_per_epoch=steps_per_epoch, epochs = num_epochs, batch_size=batch_size, callbacks=[checkpoint_callback, callback])\n",
    "\n",
    "    # Load the best model\n",
    "    best_model = load_model('cnn_model.h5')\n",
    "\n",
    "    # Evaluate on the validation data\n",
    "    val_loss, val_accuracy = best_model.evaluate(X_val, Y_val)\n",
    "\n",
    "    results[combination[0], combination[1], combination[2]] = {'accuracy': val_accuracy,  'loss': val_loss, 'history': r}\n",
    "\n",
    "    print(\"COMBINATION BEST ACCURACY: \", val_accuracy)\n",
    "\n",
    "    if val_accuracy > best_combination[1][0]:\n",
    "        best_combination = [ [combination[0], combination[1], combination[2]], [val_accuracy, val_loss, r] ]\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(3, 0.2, 0.001): {'accuracy': 0.8666999936103821, 'loss': 0.40497228503227234, 'history': <keras.src.callbacks.History object at 0x000002152F22B0A0>}, (5, 0.35, 0.001): {'accuracy': 0.8597999811172485, 'loss': 0.4356762170791626, 'history': <keras.src.callbacks.History object at 0x000002154B3987C0>}, (5, 0.2, 0.001): {'accuracy': 0.8388000130653381, 'loss': 0.4791260361671448, 'history': <keras.src.callbacks.History object at 0x000002155A902830>}}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination with best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COMBINATION: filter_size=3, dropout_rate=0.2, learning_rate=0.001\n",
      "Accuracy:  0.8666999936103821\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + f\"COMBINATION: filter_size={best_combination[0][0]}, dropout_rate={best_combination[0][1]}, learning_rate={best_combination[0][2]}\")\n",
    "print(\"Accuracy: \", best_combination[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Accuracy per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x215653d4f10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(best_combination[1][2].history['accuracy'], label='accuracy')\n",
    "plt.plot(best_combination[1][2].history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x215666025c0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(best_combination[1][2].history['loss'], label='loss')\n",
    "plt.plot(best_combination[1][2].history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the tuned model on entire train set and test using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 1.4957 - accuracy: 0.4807\n",
      "Epoch 1: accuracy improved from -inf to 0.48075, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 83s 202ms/step - loss: 1.4957 - accuracy: 0.4807\n",
      "Epoch 2/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.9651 - accuracy: 0.6579\n",
      "Epoch 2: accuracy improved from 0.48075 to 0.65788, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 75s 193ms/step - loss: 0.9651 - accuracy: 0.6579\n",
      "Epoch 3/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.7699 - accuracy: 0.7294\n",
      "Epoch 3: accuracy improved from 0.65788 to 0.72943, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 80s 205ms/step - loss: 0.7699 - accuracy: 0.7294\n",
      "Epoch 4/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.6600 - accuracy: 0.7683\n",
      "Epoch 4: accuracy improved from 0.72943 to 0.76835, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 77s 197ms/step - loss: 0.6600 - accuracy: 0.7683\n",
      "Epoch 5/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5743 - accuracy: 0.7989\n",
      "Epoch 5: accuracy improved from 0.76835 to 0.79891, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 78s 200ms/step - loss: 0.5743 - accuracy: 0.7989\n",
      "Epoch 6/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.5076 - accuracy: 0.8237\n",
      "Epoch 6: accuracy improved from 0.79891 to 0.82375, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 76s 194ms/step - loss: 0.5076 - accuracy: 0.8237\n",
      "Epoch 7/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4584 - accuracy: 0.8397\n",
      "Epoch 7: accuracy improved from 0.82375 to 0.83973, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 82s 210ms/step - loss: 0.4584 - accuracy: 0.8397\n",
      "Epoch 8/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.4113 - accuracy: 0.8570\n",
      "Epoch 8: accuracy improved from 0.83973 to 0.85699, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 79s 204ms/step - loss: 0.4113 - accuracy: 0.8570\n",
      "Epoch 9/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3644 - accuracy: 0.8706\n",
      "Epoch 9: accuracy improved from 0.85699 to 0.87063, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 78s 200ms/step - loss: 0.3644 - accuracy: 0.8706\n",
      "Epoch 10/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3372 - accuracy: 0.8824\n",
      "Epoch 10: accuracy improved from 0.87063 to 0.88236, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 79s 201ms/step - loss: 0.3372 - accuracy: 0.8824\n",
      "Epoch 11/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.3032 - accuracy: 0.8927\n",
      "Epoch 11: accuracy improved from 0.88236 to 0.89269, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 75s 191ms/step - loss: 0.3032 - accuracy: 0.8927\n",
      "Epoch 12/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.9040\n",
      "Epoch 12: accuracy improved from 0.89269 to 0.90399, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 75s 192ms/step - loss: 0.2738 - accuracy: 0.9040\n",
      "Epoch 13/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2487 - accuracy: 0.9135\n",
      "Epoch 13: accuracy improved from 0.90399 to 0.91350, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 74s 189ms/step - loss: 0.2487 - accuracy: 0.9135\n",
      "Epoch 14/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2310 - accuracy: 0.9189\n",
      "Epoch 14: accuracy improved from 0.91350 to 0.91891, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 73s 187ms/step - loss: 0.2310 - accuracy: 0.9189\n",
      "Epoch 15/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.9229\n",
      "Epoch 15: accuracy improved from 0.91891 to 0.92286, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 74s 191ms/step - loss: 0.2159 - accuracy: 0.9229\n",
      "Epoch 16/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1962 - accuracy: 0.9299\n",
      "Epoch 16: accuracy improved from 0.92286 to 0.92990, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 81s 208ms/step - loss: 0.1962 - accuracy: 0.9299\n",
      "Epoch 17/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1867 - accuracy: 0.9352\n",
      "Epoch 17: accuracy improved from 0.92990 to 0.93517, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 78s 201ms/step - loss: 0.1867 - accuracy: 0.9352\n",
      "Epoch 18/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.9408\n",
      "Epoch 18: accuracy improved from 0.93517 to 0.94083, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 82s 210ms/step - loss: 0.1717 - accuracy: 0.9408\n",
      "Epoch 19/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1583 - accuracy: 0.9450\n",
      "Epoch 19: accuracy improved from 0.94083 to 0.94496, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 72s 184ms/step - loss: 0.1583 - accuracy: 0.9450\n",
      "Epoch 20/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1576 - accuracy: 0.9456\n",
      "Epoch 20: accuracy improved from 0.94496 to 0.94564, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 77s 199ms/step - loss: 0.1576 - accuracy: 0.9456\n",
      "Epoch 21/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1471 - accuracy: 0.9496\n",
      "Epoch 21: accuracy improved from 0.94564 to 0.94959, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 77s 196ms/step - loss: 0.1471 - accuracy: 0.9496\n",
      "Epoch 22/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1391 - accuracy: 0.9514\n",
      "Epoch 22: accuracy improved from 0.94959 to 0.95142, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 76s 194ms/step - loss: 0.1391 - accuracy: 0.9514\n",
      "Epoch 23/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 0.9535\n",
      "Epoch 23: accuracy improved from 0.95142 to 0.95352, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 78s 200ms/step - loss: 0.1333 - accuracy: 0.9535\n",
      "Epoch 24/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9572\n",
      "Epoch 24: accuracy improved from 0.95352 to 0.95723, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 83s 212ms/step - loss: 0.1221 - accuracy: 0.9572\n",
      "Epoch 25/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1157 - accuracy: 0.9608\n",
      "Epoch 25: accuracy improved from 0.95723 to 0.96078, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 78s 199ms/step - loss: 0.1157 - accuracy: 0.9608\n",
      "Epoch 26/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.9589\n",
      "Epoch 26: accuracy did not improve from 0.96078\n",
      "390/390 [==============================] - 74s 191ms/step - loss: 0.1229 - accuracy: 0.9589\n",
      "Epoch 27/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.9600\n",
      "Epoch 27: accuracy did not improve from 0.96078\n",
      "390/390 [==============================] - 73s 188ms/step - loss: 0.1170 - accuracy: 0.9600\n",
      "Epoch 28/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9653\n",
      "Epoch 28: accuracy improved from 0.96078 to 0.96525, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 77s 198ms/step - loss: 0.1038 - accuracy: 0.9653\n",
      "Epoch 29/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.9652\n",
      "Epoch 29: accuracy did not improve from 0.96525\n",
      "390/390 [==============================] - 80s 205ms/step - loss: 0.1039 - accuracy: 0.9652\n",
      "Epoch 30/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9653\n",
      "Epoch 30: accuracy did not improve from 0.96525\n",
      "390/390 [==============================] - 75s 192ms/step - loss: 0.1038 - accuracy: 0.9653\n",
      "Epoch 31/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.9650\n",
      "Epoch 31: accuracy did not improve from 0.96525\n",
      "390/390 [==============================] - 75s 193ms/step - loss: 0.1025 - accuracy: 0.9650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.9672\n",
      "Epoch 32: accuracy improved from 0.96525 to 0.96722, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 71s 181ms/step - loss: 0.0962 - accuracy: 0.9672\n",
      "Epoch 33/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.9696\n",
      "Epoch 33: accuracy improved from 0.96722 to 0.96958, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 72s 183ms/step - loss: 0.0916 - accuracy: 0.9696\n",
      "Epoch 34/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9698\n",
      "Epoch 34: accuracy improved from 0.96958 to 0.96976, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 72s 185ms/step - loss: 0.0914 - accuracy: 0.9698\n",
      "Epoch 35/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0877 - accuracy: 0.9708\n",
      "Epoch 35: accuracy improved from 0.96976 to 0.97081, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 71s 182ms/step - loss: 0.0877 - accuracy: 0.9708\n",
      "Epoch 36/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.9709\n",
      "Epoch 36: accuracy improved from 0.97081 to 0.97095, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 72s 185ms/step - loss: 0.0881 - accuracy: 0.9709\n",
      "Epoch 37/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9711\n",
      "Epoch 37: accuracy improved from 0.97095 to 0.97109, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 71s 183ms/step - loss: 0.0865 - accuracy: 0.9711\n",
      "Epoch 38/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9725\n",
      "Epoch 38: accuracy improved from 0.97109 to 0.97249, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 71s 183ms/step - loss: 0.0824 - accuracy: 0.9725\n",
      "Epoch 39/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9732\n",
      "Epoch 39: accuracy improved from 0.97249 to 0.97321, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 85s 219ms/step - loss: 0.0785 - accuracy: 0.9732\n",
      "Epoch 40/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9729\n",
      "Epoch 40: accuracy did not improve from 0.97321\n",
      "390/390 [==============================] - 106s 272ms/step - loss: 0.0827 - accuracy: 0.9729\n",
      "Epoch 41/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9744\n",
      "Epoch 41: accuracy improved from 0.97321 to 0.97435, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 107s 273ms/step - loss: 0.0763 - accuracy: 0.9744\n",
      "Epoch 42/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9767\n",
      "Epoch 42: accuracy improved from 0.97435 to 0.97670, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 106s 272ms/step - loss: 0.0729 - accuracy: 0.9767\n",
      "Epoch 43/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9752\n",
      "Epoch 43: accuracy did not improve from 0.97670\n",
      "390/390 [==============================] - 106s 273ms/step - loss: 0.0758 - accuracy: 0.9752\n",
      "Epoch 44/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9782\n",
      "Epoch 44: accuracy improved from 0.97670 to 0.97822, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 107s 275ms/step - loss: 0.0663 - accuracy: 0.9782\n",
      "Epoch 45/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9744\n",
      "Epoch 45: accuracy did not improve from 0.97822\n",
      "390/390 [==============================] - 106s 273ms/step - loss: 0.0749 - accuracy: 0.9744\n",
      "Epoch 46/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9775\n",
      "Epoch 46: accuracy did not improve from 0.97822\n",
      "390/390 [==============================] - 107s 274ms/step - loss: 0.0715 - accuracy: 0.9775\n",
      "Epoch 47/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9772\n",
      "Epoch 47: accuracy did not improve from 0.97822\n",
      "390/390 [==============================] - 107s 275ms/step - loss: 0.0704 - accuracy: 0.9772\n",
      "Epoch 48/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9783\n",
      "Epoch 48: accuracy improved from 0.97822 to 0.97832, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 98s 250ms/step - loss: 0.0652 - accuracy: 0.9783\n",
      "Epoch 49/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9789\n",
      "Epoch 49: accuracy improved from 0.97832 to 0.97893, saving model to cnn_model.h5\n",
      "390/390 [==============================] - 72s 185ms/step - loss: 0.0621 - accuracy: 0.9789\n",
      "Epoch 50/50\n",
      "390/390 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.9785\n",
      "Epoch 50: accuracy did not improve from 0.97893\n",
      "390/390 [==============================] - 75s 191ms/step - loss: 0.0640 - accuracy: 0.9785\n",
      "79/79 [==============================] - 5s 59ms/step - loss: 0.7780 - accuracy: 0.8514\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = create_Model2(best_combination[0][0], best_combination[0][1], best_combination[0][2])\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "steps_per_epoch = X_train.shape[0] // batch_size\n",
    "num_epochs = 50\n",
    "\n",
    " # Define Callback\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=8, verbose=1,  restore_best_weights=True)\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    filepath='cnn_model.h5'\n",
    ")\n",
    "\n",
    "\n",
    "# Train CNN on the training data\n",
    "r = model.fit(X_train, Y_train, steps_per_epoch=steps_per_epoch, epochs = num_epochs, batch_size=batch_size, callbacks=[checkpoint_callback, callback])\n",
    "\n",
    "# Load the best model\n",
    "best_model = load_model('cnn_model.h5')\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy:  0.8514000177383423\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing accuracy: \", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
